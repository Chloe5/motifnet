{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "import pdb\n",
    "import fxns\n",
    "reload(fxns);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data_path = '../data/shuffled_examples'\n",
    "\n",
    "outbase = '../output/shuffled_examples'\n",
    "train_out_path = '%s/texttrain' % outbase\n",
    "valid_out_path = '%s/textvalidate' % outbase\n",
    "test_out_path = '%s/texttest' % outbase\n",
    "\n",
    "test_chrs = [8,9]\n",
    "valid_chrs = [10,11]\n",
    "\n",
    "blocksize = 1000 # the number of records in each generated file\n",
    "\n",
    "num_blocks = 4  # the number of blocks to write out.\n",
    "                # make small for debugging\n",
    "                # set to None to do everything\n",
    "\n",
    "text = False\n",
    "binary = True\n",
    "\n",
    "seq_len = 1000 # length in base-pairs of training sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating training set\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "creating validation set\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "creating test set\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# split data into train/validate/test\n",
    "fxns.create_shards(raw_data_path,\n",
    "            train_out_path, valid_out_path, test_out_path,\n",
    "            test_chrs, valid_chrs,\n",
    "            blocksize=blocksize,\n",
    "            text=text, binary=binary, num_blocks=num_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4000) (10, 24)\n",
      "(10, 1000, 4)\n"
     ]
    }
   ],
   "source": [
    "# print some data to make sure we got it right\n",
    "# get training data\n",
    "tf.reset_default_graph()\n",
    "(seq, label), info = fxns.get_seq_and_label(train_out_path)\n",
    "seq_batch, label_batch = tf.train.shuffle_batch([seq, label],\n",
    "    batch_size=10,\n",
    "    capacity=100,\n",
    "    min_after_dequeue=50)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    # read one batch of seqs and labels\n",
    "    _seq_batch, _label_batch = sess.run([seq_batch, label_batch])\n",
    "    \n",
    "    # print their shapes\n",
    "    print _seq_batch.shape, _label_batch.shape\n",
    "    \n",
    "    # see if we can re-shape the sequences to what we need\n",
    "    # this line should produce a tensor that is batch_size x seq_len x 4\n",
    "    print sess.run(tf.reshape(seq_batch, (-1, seq_len, 4))).shape\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
