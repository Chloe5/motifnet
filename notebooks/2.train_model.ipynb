{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "import pdb\n",
    "import fxns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data locations\n",
    "raw_data_path = '../data/shuffled_examples'\n",
    "outbase = '../output/shuffled_examples'\n",
    "train_out_path = '%s/texttrain' % outbase\n",
    "valid_out_path = '%s/textvalidate' % outbase\n",
    "test_out_path = '%s/texttest' % outbase\n",
    "\n",
    "# training hyperparameters\n",
    "batch_size = 50\n",
    "num_batches_in_train = int(434786 / batch_size)\n",
    "num_epochs = 10\n",
    "capacity = 2000\n",
    "min_after_dequeue = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# retrieving models\n",
    "global_step_to_load = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs are of size 4000\n",
      "outputs are of size 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/pandas/core/series.py:2890: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  infer_datetime_format=infer_datetime_format)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# get training data\n",
    "(seq, label), info = fxns.get_seq_and_label(train_out_path)\n",
    "seq_batch, label_batch = tf.train.shuffle_batch([seq, label],\n",
    "    batch_size=batch_size,\n",
    "    capacity=capacity,\n",
    "    min_after_dequeue=min_after_dequeue)\n",
    "print('inputs are of size', info['seq_len'])\n",
    "\n",
    "# get validation data\n",
    "(seqv, labelv), infov = fxns.get_seq_and_label(valid_out_path)\n",
    "seqv_batch, labelv_batch = tf.train.shuffle_batch([seqv, labelv],\n",
    "    batch_size=batch_size,\n",
    "    capacity=capacity,\n",
    "    min_after_dequeue=min_after_dequeue)\n",
    "print('outputs are of size', info['label_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0\n",
      "250.0\n",
      "125.0\n",
      "4000 h 15 125.0\n"
     ]
    }
   ],
   "source": [
    "# # get model -- logistic\n",
    "# import logreg_model\n",
    "# modelname='logreg'\n",
    "# X, Y, loss, logits = logreg_model.get_logreg_model(info['seq_len'], info['label_len'])\n",
    "\n",
    "# get model -- generic convnet\n",
    "import novel_model; reload(novel_model)\n",
    "modelname='freeconv'\n",
    "#conv_infos = [(7,(1,20),(2,2),4),(5,(1,20),(2,2),7)]#, (8,(1,20),(2,2),5)]\n",
    "conv_infos = [(14,(1,21),(2,2),2,4),(14,(1,8),(2,2),2,14),(7,(1,5),(2,2),2,14)]#, (8,(1,20),(2,2),5)]\n",
    "X, Y, loss, logits = novel_model.get_novel_model(info['seq_len'], info['label_len'], conv_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate,\n",
    "                                                 name='SGD-Optimizer')\n",
    "    update = optimizer.minimize(loss)\n",
    "\n",
    "# define other summaries we want\n",
    "with tf.name_scope('summaries'):\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.histogram('histogram-loss', loss)\n",
    "    summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 global_step 25 i 24 Avg loss in epoch(incomplete): 0.4555277693271637\n",
      "Epoch: 0 global_step 50 i 49 Avg loss in epoch(incomplete): 0.33252002477645876\n",
      "Epoch: 0 global_step 75 i 74 Avg loss in epoch(incomplete): 0.2789812296628952\n",
      "Epoch: 0 global_step 100 i 99 Avg loss in epoch(incomplete): 0.25089493215084074\n",
      "Epoch: 0 global_step 125 i 124 Avg loss in epoch(incomplete): 0.23400295746326447\n",
      "Epoch: 0 global_step 150 i 149 Avg loss in epoch(incomplete): 0.22268974483013154\n",
      "Epoch: 0 global_step 175 i 174 Avg loss in epoch(incomplete): 0.21443751573562622\n",
      "Epoch: 0 global_step 200 i 199 Avg loss in epoch(incomplete): 0.20836703836917878\n",
      "Epoch: 0 global_step 225 i 224 Avg loss in epoch(incomplete): 0.2035365508000056\n",
      "saving\n",
      "Epoch: 0 global_step 250 i 249 Avg loss in epoch(incomplete): 0.19972987306118012\n",
      "Epoch: 0 global_step 250 i 249 Avg loss in epoch(incomplete): 0.19972987306118012\n",
      "Epoch: 0 global_step 275 i 274 Avg loss in epoch(incomplete): 0.19665270512754268\n",
      "Epoch: 0 global_step 300 i 299 Avg loss in epoch(incomplete): 0.1941363670428594\n",
      "Epoch: 0 global_step 325 i 324 Avg loss in epoch(incomplete): 0.19187192971889788\n",
      "Epoch: 0 global_step 350 i 349 Avg loss in epoch(incomplete): 0.18998707298721587\n",
      "Epoch: 0 global_step 375 i 374 Avg loss in epoch(incomplete): 0.18832558675607045\n",
      "Epoch: 0 global_step 400 i 399 Avg loss in epoch(incomplete): 0.18686461981385946\n",
      "Epoch: 0 global_step 425 i 424 Avg loss in epoch(incomplete): 0.1855136889920515\n",
      "Epoch: 0 global_step 450 i 449 Avg loss in epoch(incomplete): 0.18434669391976463\n",
      "Epoch: 0 global_step 475 i 474 Avg loss in epoch(incomplete): 0.183391287734634\n",
      "saving\n",
      "Epoch: 0 global_step 500 i 499 Avg loss in epoch(incomplete): 0.18245495173335075\n",
      "Epoch: 0 global_step 500 i 499 Avg loss in epoch(incomplete): 0.18245495173335075\n",
      "Epoch: 0 global_step 525 i 524 Avg loss in epoch(incomplete): 0.18166715641816458\n",
      "Epoch: 0 global_step 550 i 549 Avg loss in epoch(incomplete): 0.18089755126021126\n",
      "Epoch: 0 global_step 575 i 574 Avg loss in epoch(incomplete): 0.1802372503021489\n",
      "Epoch: 0 global_step 600 i 599 Avg loss in epoch(incomplete): 0.1796099771310886\n",
      "Epoch: 0 global_step 625 i 624 Avg loss in epoch(incomplete): 0.17900426943302156\n",
      "Epoch: 0 global_step 650 i 649 Avg loss in epoch(incomplete): 0.1784735265832681\n",
      "Epoch: 0 global_step 675 i 674 Avg loss in epoch(incomplete): 0.17795912638858513\n",
      "Epoch: 0 global_step 700 i 699 Avg loss in epoch(incomplete): 0.17746765134590012\n",
      "Epoch: 0 global_step 725 i 724 Avg loss in epoch(incomplete): 0.1770744329690933\n",
      "saving\n",
      "Epoch: 0 global_step 750 i 749 Avg loss in epoch(incomplete): 0.1766392983396848\n",
      "Epoch: 0 global_step 750 i 749 Avg loss in epoch(incomplete): 0.1766392983396848\n",
      "Epoch: 0 global_step 775 i 774 Avg loss in epoch(incomplete): 0.17627539942341466\n",
      "Epoch: 0 global_step 800 i 799 Avg loss in epoch(incomplete): 0.1759050010703504\n",
      "Epoch: 0 global_step 825 i 824 Avg loss in epoch(incomplete): 0.17558244721456007\n",
      "Epoch: 0 global_step 850 i 849 Avg loss in epoch(incomplete): 0.17529075589250115\n",
      "Epoch: 0 global_step 875 i 874 Avg loss in epoch(incomplete): 0.1750068212747574\n",
      "Epoch: 0 global_step 900 i 899 Avg loss in epoch(incomplete): 0.17470330054561298\n",
      "Epoch: 0 global_step 925 i 924 Avg loss in epoch(incomplete): 0.17442000951315906\n",
      "Epoch: 0 global_step 950 i 949 Avg loss in epoch(incomplete): 0.1741324364354736\n",
      "Epoch: 0 global_step 975 i 974 Avg loss in epoch(incomplete): 0.17392451509451254\n",
      "saving\n",
      "Epoch: 0 global_step 1000 i 999 Avg loss in epoch(incomplete): 0.173706138625741\n",
      "Epoch: 0 global_step 1000 i 999 Avg loss in epoch(incomplete): 0.173706138625741\n",
      "Epoch: 0 global_step 1025 i 1024 Avg loss in epoch(incomplete): 0.17349770324986155\n",
      "Epoch: 0 global_step 1050 i 1049 Avg loss in epoch(incomplete): 0.17331293438162124\n",
      "Epoch: 0 global_step 1075 i 1074 Avg loss in epoch(incomplete): 0.17311460555985916\n",
      "Epoch: 0 global_step 1100 i 1099 Avg loss in epoch(incomplete): 0.17295481837608598\n",
      "Epoch: 0 global_step 1125 i 1124 Avg loss in epoch(incomplete): 0.17277780244085525\n",
      "Epoch: 0 global_step 1150 i 1149 Avg loss in epoch(incomplete): 0.17259750069483468\n",
      "Epoch: 0 global_step 1175 i 1174 Avg loss in epoch(incomplete): 0.1724415478554178\n",
      "Epoch: 0 global_step 1200 i 1199 Avg loss in epoch(incomplete): 0.17227638053397337\n",
      "Epoch: 0 global_step 1225 i 1224 Avg loss in epoch(incomplete): 0.17211625398421773\n",
      "saving\n",
      "Epoch: 0 global_step 1250 i 1249 Avg loss in epoch(incomplete): 0.17197249530553818\n",
      "Epoch: 0 global_step 1250 i 1249 Avg loss in epoch(incomplete): 0.17197249530553818\n",
      "Epoch: 0 global_step 1275 i 1274 Avg loss in epoch(incomplete): 0.17185488075602287\n",
      "Epoch: 0 global_step 1300 i 1299 Avg loss in epoch(incomplete): 0.17171513192928756\n",
      "Epoch: 0 global_step 1325 i 1324 Avg loss in epoch(incomplete): 0.1715901559928678\n",
      "Epoch: 0 global_step 1350 i 1349 Avg loss in epoch(incomplete): 0.17144885852381034\n",
      "Epoch: 0 global_step 1375 i 1374 Avg loss in epoch(incomplete): 0.171327676133676\n",
      "Epoch: 0 global_step 1400 i 1399 Avg loss in epoch(incomplete): 0.17122473326112542\n",
      "Epoch: 0 global_step 1425 i 1424 Avg loss in epoch(incomplete): 0.1711115738278941\n",
      "Epoch: 0 global_step 1450 i 1449 Avg loss in epoch(incomplete): 0.17101796172816178\n",
      "Epoch: 0 global_step 1475 i 1474 Avg loss in epoch(incomplete): 0.17091717111862312\n",
      "saving\n",
      "Epoch: 0 global_step 1500 i 1499 Avg loss in epoch(incomplete): 0.17082463821768762\n",
      "Epoch: 0 global_step 1500 i 1499 Avg loss in epoch(incomplete): 0.17082463821768762\n",
      "Epoch: 0 global_step 1525 i 1524 Avg loss in epoch(incomplete): 0.17073218173668034\n",
      "Epoch: 0 global_step 1550 i 1549 Avg loss in epoch(incomplete): 0.17066090213675653\n",
      "Epoch: 0 global_step 1575 i 1574 Avg loss in epoch(incomplete): 0.1705758209644802\n",
      "Epoch: 0 global_step 1600 i 1599 Avg loss in epoch(incomplete): 0.17049755457788707\n",
      "Epoch: 0 global_step 1625 i 1624 Avg loss in epoch(incomplete): 0.17042371987379515\n",
      "Epoch: 0 global_step 1650 i 1649 Avg loss in epoch(incomplete): 0.17033777778798884\n",
      "Epoch: 0 global_step 1675 i 1674 Avg loss in epoch(incomplete): 0.17026652995330185\n",
      "Epoch: 0 global_step 1700 i 1699 Avg loss in epoch(incomplete): 0.17018882307059624\n",
      "Epoch: 0 global_step 1725 i 1724 Avg loss in epoch(incomplete): 0.17010292817717013\n",
      "saving\n",
      "Epoch: 0 global_step 1750 i 1749 Avg loss in epoch(incomplete): 0.170030531338283\n",
      "Epoch: 0 global_step 1750 i 1749 Avg loss in epoch(incomplete): 0.170030531338283\n",
      "Epoch: 0 global_step 1775 i 1774 Avg loss in epoch(incomplete): 0.1699624166606178\n",
      "Epoch: 0 global_step 1800 i 1799 Avg loss in epoch(incomplete): 0.16989662153025467\n",
      "Epoch: 0 global_step 1825 i 1824 Avg loss in epoch(incomplete): 0.16982505279861085\n",
      "Epoch: 0 global_step 1850 i 1849 Avg loss in epoch(incomplete): 0.1697548995710708\n",
      "Epoch: 0 global_step 1875 i 1874 Avg loss in epoch(incomplete): 0.1697121078014374\n",
      "Epoch: 0 global_step 1900 i 1899 Avg loss in epoch(incomplete): 0.16965860755035753\n",
      "Epoch: 0 global_step 1925 i 1924 Avg loss in epoch(incomplete): 0.16959141781577816\n",
      "Epoch: 0 global_step 1950 i 1949 Avg loss in epoch(incomplete): 0.16952947547802558\n",
      "Epoch: 0 global_step 1975 i 1974 Avg loss in epoch(incomplete): 0.16945576467091525\n",
      "saving\n",
      "Epoch: 0 global_step 2000 i 1999 Avg loss in epoch(incomplete): 0.16940925028920173\n",
      "Epoch: 0 global_step 2000 i 1999 Avg loss in epoch(incomplete): 0.16940925028920173\n",
      "Epoch: 0 global_step 2025 i 2024 Avg loss in epoch(incomplete): 0.16936913621278457\n",
      "Epoch: 0 global_step 2050 i 2049 Avg loss in epoch(incomplete): 0.16931539389418393\n",
      "Epoch: 0 global_step 2075 i 2074 Avg loss in epoch(incomplete): 0.16925320908965835\n",
      "Epoch: 0 global_step 2100 i 2099 Avg loss in epoch(incomplete): 0.16920198013385138\n",
      "Epoch: 0 global_step 2125 i 2124 Avg loss in epoch(incomplete): 0.16914179067050708\n",
      "Epoch: 0 global_step 2150 i 2149 Avg loss in epoch(incomplete): 0.16910054059915763\n",
      "Epoch: 0 global_step 2175 i 2174 Avg loss in epoch(incomplete): 0.16906087502665904\n",
      "Epoch: 0 global_step 2200 i 2199 Avg loss in epoch(incomplete): 0.169016277322715\n",
      "Epoch: 0 global_step 2225 i 2224 Avg loss in epoch(incomplete): 0.16897578510005823\n",
      "saving\n",
      "Epoch: 0 global_step 2250 i 2249 Avg loss in epoch(incomplete): 0.1689225425918897\n",
      "Epoch: 0 global_step 2250 i 2249 Avg loss in epoch(incomplete): 0.1689225425918897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 global_step 2275 i 2274 Avg loss in epoch(incomplete): 0.16888985075793422\n",
      "Epoch: 0 global_step 2300 i 2299 Avg loss in epoch(incomplete): 0.16885713125700536\n",
      "Epoch: 0 global_step 2325 i 2324 Avg loss in epoch(incomplete): 0.16881459568777393\n",
      "Epoch: 0 global_step 2350 i 2349 Avg loss in epoch(incomplete): 0.16877209795282241\n",
      "Epoch: 0 global_step 2375 i 2374 Avg loss in epoch(incomplete): 0.1687316463370072\n",
      "Epoch: 0 global_step 2400 i 2399 Avg loss in epoch(incomplete): 0.1687027858446042\n",
      "Epoch: 0 global_step 2425 i 2424 Avg loss in epoch(incomplete): 0.1686640146098186\n",
      "Epoch: 0 global_step 2450 i 2449 Avg loss in epoch(incomplete): 0.1686280252069843\n",
      "Epoch: 0 global_step 2475 i 2474 Avg loss in epoch(incomplete): 0.16859648368575356\n",
      "saving\n",
      "Epoch: 0 global_step 2500 i 2499 Avg loss in epoch(incomplete): 0.16856838999986648\n",
      "Epoch: 0 global_step 2500 i 2499 Avg loss in epoch(incomplete): 0.16856838999986648\n",
      "Epoch: 0 global_step 2525 i 2524 Avg loss in epoch(incomplete): 0.1685291317547902\n",
      "Epoch: 0 global_step 2550 i 2549 Avg loss in epoch(incomplete): 0.16849941968333487\n",
      "Epoch: 0 global_step 2575 i 2574 Avg loss in epoch(incomplete): 0.1684809435108333\n",
      "Epoch: 0 global_step 2600 i 2599 Avg loss in epoch(incomplete): 0.16844494742842822\n",
      "Epoch: 0 global_step 2625 i 2624 Avg loss in epoch(incomplete): 0.16841174606482187\n",
      "Epoch: 0 global_step 2650 i 2649 Avg loss in epoch(incomplete): 0.1683891928814492\n",
      "Epoch: 0 global_step 2675 i 2674 Avg loss in epoch(incomplete): 0.16835717803406938\n",
      "Epoch: 0 global_step 2700 i 2699 Avg loss in epoch(incomplete): 0.16832718194634827\n",
      "Epoch: 0 global_step 2725 i 2724 Avg loss in epoch(incomplete): 0.168300475576602\n",
      "saving\n",
      "Epoch: 0 global_step 2750 i 2749 Avg loss in epoch(incomplete): 0.16827188082716682\n",
      "Epoch: 0 global_step 2750 i 2749 Avg loss in epoch(incomplete): 0.16827188082716682\n",
      "Epoch: 0 global_step 2775 i 2774 Avg loss in epoch(incomplete): 0.16824509936947007\n",
      "Epoch: 0 global_step 2800 i 2799 Avg loss in epoch(incomplete): 0.16821925078651734\n",
      "Epoch: 0 global_step 2825 i 2824 Avg loss in epoch(incomplete): 0.16819352901614873\n",
      "Epoch: 0 global_step 2850 i 2849 Avg loss in epoch(incomplete): 0.16817035052337145\n",
      "Epoch: 0 global_step 2875 i 2874 Avg loss in epoch(incomplete): 0.16813671032242153\n",
      "Epoch: 0 global_step 2900 i 2899 Avg loss in epoch(incomplete): 0.1681079548648719\n",
      "Epoch: 0 global_step 2925 i 2924 Avg loss in epoch(incomplete): 0.1680773967453557\n",
      "Epoch: 0 global_step 2950 i 2949 Avg loss in epoch(incomplete): 0.16805237558433564\n",
      "Epoch: 0 global_step 2975 i 2974 Avg loss in epoch(incomplete): 0.16803568213927644\n",
      "saving\n",
      "Epoch: 0 global_step 3000 i 2999 Avg loss in epoch(incomplete): 0.16800723696748415\n",
      "Epoch: 0 global_step 3000 i 2999 Avg loss in epoch(incomplete): 0.16800723696748415\n",
      "Epoch: 0 global_step 3025 i 3024 Avg loss in epoch(incomplete): 0.16797535865760047\n",
      "Epoch: 0 global_step 3050 i 3049 Avg loss in epoch(incomplete): 0.1679560346388426\n",
      "Epoch: 0 global_step 3075 i 3074 Avg loss in epoch(incomplete): 0.16792867801053737\n",
      "Epoch: 0 global_step 3100 i 3099 Avg loss in epoch(incomplete): 0.16790590360760688\n",
      "Epoch: 0 global_step 3125 i 3124 Avg loss in epoch(incomplete): 0.1678873304080963\n",
      "Epoch: 0 global_step 3150 i 3149 Avg loss in epoch(incomplete): 0.16786392216171536\n",
      "Epoch: 0 global_step 3175 i 3174 Avg loss in epoch(incomplete): 0.167844725321597\n",
      "Epoch: 0 global_step 3200 i 3199 Avg loss in epoch(incomplete): 0.16782704539597035\n",
      "Epoch: 0 global_step 3225 i 3224 Avg loss in epoch(incomplete): 0.16780474518620692\n",
      "saving\n",
      "Epoch: 0 global_step 3250 i 3249 Avg loss in epoch(incomplete): 0.16778486320605646\n",
      "Epoch: 0 global_step 3250 i 3249 Avg loss in epoch(incomplete): 0.16778486320605646\n",
      "Epoch: 0 global_step 3275 i 3274 Avg loss in epoch(incomplete): 0.1677618480729693\n",
      "Epoch: 0 global_step 3300 i 3299 Avg loss in epoch(incomplete): 0.1677418147614508\n",
      "Epoch: 0 global_step 3325 i 3324 Avg loss in epoch(incomplete): 0.16772031230585915\n",
      "Epoch: 0 global_step 3350 i 3349 Avg loss in epoch(incomplete): 0.16770200058595458\n",
      "Epoch: 0 global_step 3375 i 3374 Avg loss in epoch(incomplete): 0.16769195110268062\n",
      "Epoch: 0 global_step 3400 i 3399 Avg loss in epoch(incomplete): 0.1676792868665036\n",
      "Epoch: 0 global_step 3425 i 3424 Avg loss in epoch(incomplete): 0.16766079756900343\n",
      "Epoch: 0 global_step 3450 i 3449 Avg loss in epoch(incomplete): 0.1676426011280737\n",
      "Epoch: 0 global_step 3475 i 3474 Avg loss in epoch(incomplete): 0.16762428002820598\n",
      "saving\n",
      "Epoch: 0 global_step 3500 i 3499 Avg loss in epoch(incomplete): 0.16759908757465225\n",
      "Epoch: 0 global_step 3500 i 3499 Avg loss in epoch(incomplete): 0.16759908757465225\n",
      "Epoch: 0 global_step 3525 i 3524 Avg loss in epoch(incomplete): 0.1675833417549201\n",
      "Epoch: 0 global_step 3550 i 3549 Avg loss in epoch(incomplete): 0.16756581242655363\n",
      "Epoch: 0 global_step 3575 i 3574 Avg loss in epoch(incomplete): 0.16756560960432867\n",
      "Epoch: 0 global_step 3600 i 3599 Avg loss in epoch(incomplete): 0.16755183363126383\n",
      "Epoch: 0 global_step 3625 i 3624 Avg loss in epoch(incomplete): 0.16752599913087385\n",
      "Epoch: 0 global_step 3650 i 3649 Avg loss in epoch(incomplete): 0.16751373983817558\n",
      "Epoch: 0 global_step 3675 i 3674 Avg loss in epoch(incomplete): 0.1674995614436208\n",
      "Epoch: 0 global_step 3700 i 3699 Avg loss in epoch(incomplete): 0.16747864350676536\n",
      "Epoch: 0 global_step 3725 i 3724 Avg loss in epoch(incomplete): 0.1674605912130151\n",
      "saving\n",
      "Epoch: 0 global_step 3750 i 3749 Avg loss in epoch(incomplete): 0.16743929926554363\n",
      "Epoch: 0 global_step 3750 i 3749 Avg loss in epoch(incomplete): 0.16743929926554363\n",
      "Epoch: 0 global_step 3775 i 3774 Avg loss in epoch(incomplete): 0.16742774475883965\n",
      "Epoch: 0 global_step 3800 i 3799 Avg loss in epoch(incomplete): 0.16741362481917205\n",
      "Epoch: 0 global_step 3825 i 3824 Avg loss in epoch(incomplete): 0.16740957519197774\n",
      "Epoch: 0 global_step 3850 i 3849 Avg loss in epoch(incomplete): 0.16739144404600192\n",
      "Epoch: 0 global_step 3875 i 3874 Avg loss in epoch(incomplete): 0.16738360583782197\n",
      "Epoch: 0 global_step 3900 i 3899 Avg loss in epoch(incomplete): 0.1673687681211875\n",
      "Epoch: 0 global_step 3925 i 3924 Avg loss in epoch(incomplete): 0.1673589032812483\n",
      "Epoch: 0 global_step 3950 i 3949 Avg loss in epoch(incomplete): 0.16734453332952307\n",
      "Epoch: 0 global_step 3975 i 3974 Avg loss in epoch(incomplete): 0.16733342063501946\n",
      "saving\n",
      "Epoch: 0 global_step 4000 i 3999 Avg loss in epoch(incomplete): 0.1673192159049213\n",
      "Epoch: 0 global_step 4000 i 3999 Avg loss in epoch(incomplete): 0.1673192159049213\n",
      "Epoch: 0 global_step 4025 i 4024 Avg loss in epoch(incomplete): 0.16730560484510032\n",
      "Epoch: 0 global_step 4050 i 4049 Avg loss in epoch(incomplete): 0.16728327333191295\n",
      "Epoch: 0 global_step 4075 i 4074 Avg loss in epoch(incomplete): 0.16726565401612614\n",
      "Epoch: 0 global_step 4100 i 4099 Avg loss in epoch(incomplete): 0.16725008097000238\n",
      "Epoch: 0 global_step 4125 i 4124 Avg loss in epoch(incomplete): 0.1672394606922612\n",
      "Epoch: 0 global_step 4150 i 4149 Avg loss in epoch(incomplete): 0.16721950654164855\n",
      "Epoch: 0 global_step 4175 i 4174 Avg loss in epoch(incomplete): 0.16720642603799968\n",
      "Epoch: 0 global_step 4200 i 4199 Avg loss in epoch(incomplete): 0.16719817313409988\n",
      "Epoch: 0 global_step 4225 i 4224 Avg loss in epoch(incomplete): 0.1671812552354745\n",
      "saving\n",
      "Epoch: 0 global_step 4250 i 4249 Avg loss in epoch(incomplete): 0.16717027800223408\n",
      "Epoch: 0 global_step 4250 i 4249 Avg loss in epoch(incomplete): 0.16717027800223408\n",
      "Epoch: 0 global_step 4275 i 4274 Avg loss in epoch(incomplete): 0.1671608629805303\n",
      "Epoch: 0 global_step 4300 i 4299 Avg loss in epoch(incomplete): 0.16715066230920858\n",
      "Epoch: 0 global_step 4325 i 4324 Avg loss in epoch(incomplete): 0.16713848002384163\n",
      "Epoch: 0 global_step 4350 i 4349 Avg loss in epoch(incomplete): 0.1671258436160526\n",
      "Epoch: 0 global_step 4375 i 4374 Avg loss in epoch(incomplete): 0.16711037915093557\n",
      "Epoch: 0 global_step 4400 i 4399 Avg loss in epoch(incomplete): 0.16709249130704187\n",
      "Epoch: 0 global_step 4425 i 4424 Avg loss in epoch(incomplete): 0.16707786362386692\n",
      "Epoch: 0 global_step 4450 i 4449 Avg loss in epoch(incomplete): 0.16706503279423446\n",
      "Epoch: 0 global_step 4475 i 4474 Avg loss in epoch(incomplete): 0.16706014294198104\n",
      "saving\n",
      "Epoch: 0 global_step 4500 i 4499 Avg loss in epoch(incomplete): 0.16705010888973873\n",
      "Epoch: 0 global_step 4500 i 4499 Avg loss in epoch(incomplete): 0.16705010888973873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 global_step 4525 i 4524 Avg loss in epoch(incomplete): 0.16703673733532098\n",
      "Epoch: 0 global_step 4550 i 4549 Avg loss in epoch(incomplete): 0.16702528297901154\n",
      "Epoch: 0 global_step 4575 i 4574 Avg loss in epoch(incomplete): 0.16701887124548845\n",
      "Epoch: 0 global_step 4600 i 4599 Avg loss in epoch(incomplete): 0.16701051518968915\n",
      "Epoch: 0 global_step 4625 i 4624 Avg loss in epoch(incomplete): 0.16699829885444126\n",
      "Epoch: 0 global_step 4650 i 4649 Avg loss in epoch(incomplete): 0.16698510623747304\n",
      "Epoch: 0 global_step 4675 i 4674 Avg loss in epoch(incomplete): 0.1669716313242275\n",
      "Epoch: 0 global_step 4700 i 4699 Avg loss in epoch(incomplete): 0.16696330473144003\n",
      "Epoch: 0 global_step 4725 i 4724 Avg loss in epoch(incomplete): 0.1669522609944066\n",
      "saving\n",
      "Epoch: 0 global_step 4750 i 4749 Avg loss in epoch(incomplete): 0.16694336576524535\n",
      "Epoch: 0 global_step 4750 i 4749 Avg loss in epoch(incomplete): 0.16694336576524535\n",
      "Epoch: 0 global_step 4775 i 4774 Avg loss in epoch(incomplete): 0.16693409762145336\n",
      "Epoch: 0 global_step 4800 i 4799 Avg loss in epoch(incomplete): 0.16692773870502908\n",
      "Epoch: 0 global_step 4825 i 4824 Avg loss in epoch(incomplete): 0.1669175933340053\n",
      "Epoch: 0 global_step 4850 i 4849 Avg loss in epoch(incomplete): 0.16690954307919925\n",
      "Epoch: 0 global_step 4875 i 4874 Avg loss in epoch(incomplete): 0.16690284611322942\n",
      "Epoch: 0 global_step 4900 i 4899 Avg loss in epoch(incomplete): 0.1668918487551261\n",
      "Epoch: 0 global_step 4925 i 4924 Avg loss in epoch(incomplete): 0.1668806588891799\n",
      "Epoch: 0 global_step 4950 i 4949 Avg loss in epoch(incomplete): 0.1668730477522118\n",
      "Epoch: 0 global_step 4975 i 4974 Avg loss in epoch(incomplete): 0.16686010983122054\n",
      "saving\n",
      "Epoch: 0 global_step 5000 i 4999 Avg loss in epoch(incomplete): 0.166851662966609\n",
      "Epoch: 0 global_step 5000 i 4999 Avg loss in epoch(incomplete): 0.166851662966609\n",
      "Epoch: 0 global_step 5025 i 5024 Avg loss in epoch(incomplete): 0.16684081085285737\n",
      "Epoch: 0 global_step 5050 i 5049 Avg loss in epoch(incomplete): 0.16683144753817283\n",
      "Epoch: 0 global_step 5075 i 5074 Avg loss in epoch(incomplete): 0.16681953862382862\n",
      "Epoch: 0 global_step 5100 i 5099 Avg loss in epoch(incomplete): 0.16681040277668074\n",
      "Epoch: 0 global_step 5125 i 5124 Avg loss in epoch(incomplete): 0.16679928877004763\n",
      "Epoch: 0 global_step 5150 i 5149 Avg loss in epoch(incomplete): 0.16679332115407128\n",
      "Epoch: 0 global_step 5175 i 5174 Avg loss in epoch(incomplete): 0.16678641852261364\n",
      "Epoch: 0 global_step 5200 i 5199 Avg loss in epoch(incomplete): 0.1667792724789335\n",
      "Epoch: 0 global_step 5225 i 5224 Avg loss in epoch(incomplete): 0.16677145860411904\n",
      "saving\n",
      "Epoch: 0 global_step 5250 i 5249 Avg loss in epoch(incomplete): 0.1667599552756264\n",
      "Epoch: 0 global_step 5250 i 5249 Avg loss in epoch(incomplete): 0.1667599552756264\n",
      "Epoch: 0 global_step 5275 i 5274 Avg loss in epoch(incomplete): 0.16674949327068872\n",
      "Epoch: 0 global_step 5300 i 5299 Avg loss in epoch(incomplete): 0.1667468140850652\n",
      "Epoch: 0 global_step 5325 i 5324 Avg loss in epoch(incomplete): 0.16673830072085064\n",
      "Epoch: 0 global_step 5350 i 5349 Avg loss in epoch(incomplete): 0.16672946449473638\n",
      "Epoch: 0 global_step 5375 i 5374 Avg loss in epoch(incomplete): 0.16672172771775445\n",
      "Epoch: 0 global_step 5400 i 5399 Avg loss in epoch(incomplete): 0.16671773281914218\n",
      "Epoch: 0 global_step 5425 i 5424 Avg loss in epoch(incomplete): 0.16670454976196114\n",
      "Epoch: 0 global_step 5450 i 5449 Avg loss in epoch(incomplete): 0.16669788153346526\n",
      "Epoch: 0 global_step 5475 i 5474 Avg loss in epoch(incomplete): 0.16668731157638167\n",
      "saving\n",
      "Epoch: 0 global_step 5500 i 5499 Avg loss in epoch(incomplete): 0.16668163779377937\n",
      "Epoch: 0 global_step 5500 i 5499 Avg loss in epoch(incomplete): 0.16668163779377937\n",
      "Epoch: 0 global_step 5525 i 5524 Avg loss in epoch(incomplete): 0.16667214819478773\n",
      "Epoch: 0 global_step 5550 i 5549 Avg loss in epoch(incomplete): 0.16666677650299158\n",
      "Epoch: 0 global_step 5575 i 5574 Avg loss in epoch(incomplete): 0.16665980130567679\n",
      "Epoch: 0 global_step 5600 i 5599 Avg loss in epoch(incomplete): 0.1666512671219451\n",
      "Epoch: 0 global_step 5625 i 5624 Avg loss in epoch(incomplete): 0.16664503249327342\n",
      "Epoch: 0 global_step 5650 i 5649 Avg loss in epoch(incomplete): 0.16663706395742112\n",
      "Epoch: 0 global_step 5675 i 5674 Avg loss in epoch(incomplete): 0.16663146315429705\n",
      "Epoch: 0 global_step 5700 i 5699 Avg loss in epoch(incomplete): 0.16662788349546884\n",
      "Epoch: 0 global_step 5725 i 5724 Avg loss in epoch(incomplete): 0.16662324234908324\n",
      "saving\n",
      "Epoch: 0 global_step 5750 i 5749 Avg loss in epoch(incomplete): 0.16661721638492916\n",
      "Epoch: 0 global_step 5750 i 5749 Avg loss in epoch(incomplete): 0.16661721638492916\n",
      "Epoch: 0 global_step 5775 i 5774 Avg loss in epoch(incomplete): 0.1666098407336644\n",
      "Epoch: 0 global_step 5800 i 5799 Avg loss in epoch(incomplete): 0.16660152547061444\n",
      "Epoch: 0 global_step 5825 i 5824 Avg loss in epoch(incomplete): 0.16659447392936427\n",
      "Epoch: 0 global_step 5850 i 5849 Avg loss in epoch(incomplete): 0.166584705537201\n",
      "Epoch: 0 global_step 5875 i 5874 Avg loss in epoch(incomplete): 0.16658177234517768\n",
      "Epoch: 0 global_step 5900 i 5899 Avg loss in epoch(incomplete): 0.16657391616853617\n",
      "Epoch: 0 global_step 5925 i 5924 Avg loss in epoch(incomplete): 0.1665624949398926\n",
      "Epoch: 0 global_step 5950 i 5949 Avg loss in epoch(incomplete): 0.16655470723614973\n",
      "Epoch: 0 global_step 5975 i 5974 Avg loss in epoch(incomplete): 0.16654493509226764\n",
      "saving\n",
      "Epoch: 0 global_step 6000 i 5999 Avg loss in epoch(incomplete): 0.1665344689289729\n",
      "Epoch: 0 global_step 6000 i 5999 Avg loss in epoch(incomplete): 0.1665344689289729\n",
      "Epoch: 0 global_step 6025 i 6024 Avg loss in epoch(incomplete): 0.16653029825430193\n",
      "Epoch: 0 global_step 6050 i 6049 Avg loss in epoch(incomplete): 0.16652286631509292\n",
      "Epoch: 0 global_step 6075 i 6074 Avg loss in epoch(incomplete): 0.16651489966445499\n",
      "Epoch: 0 global_step 6100 i 6099 Avg loss in epoch(incomplete): 0.16650992908927262\n",
      "Epoch: 0 global_step 6125 i 6124 Avg loss in epoch(incomplete): 0.16650400638823606\n",
      "Epoch: 0 global_step 6150 i 6149 Avg loss in epoch(incomplete): 0.16649850917056325\n",
      "Epoch: 0 global_step 6175 i 6174 Avg loss in epoch(incomplete): 0.16649335740790194\n",
      "Epoch: 0 global_step 6200 i 6199 Avg loss in epoch(incomplete): 0.16648917177271458\n",
      "Epoch: 0 global_step 6225 i 6224 Avg loss in epoch(incomplete): 0.16648554001467294\n",
      "saving\n",
      "Epoch: 0 global_step 6250 i 6249 Avg loss in epoch(incomplete): 0.1664798167848587\n",
      "Epoch: 0 global_step 6250 i 6249 Avg loss in epoch(incomplete): 0.1664798167848587\n",
      "Epoch: 0 global_step 6275 i 6274 Avg loss in epoch(incomplete): 0.16647704012365455\n",
      "Epoch: 0 global_step 6300 i 6299 Avg loss in epoch(incomplete): 0.16647353795549227\n",
      "Epoch: 0 global_step 6325 i 6324 Avg loss in epoch(incomplete): 0.16647082668754895\n",
      "Epoch: 0 global_step 6350 i 6349 Avg loss in epoch(incomplete): 0.16646704620733035\n",
      "Epoch: 0 global_step 6375 i 6374 Avg loss in epoch(incomplete): 0.1664600604211583\n",
      "Epoch: 0 global_step 6400 i 6399 Avg loss in epoch(incomplete): 0.16645430153468624\n",
      "Epoch: 0 global_step 6425 i 6424 Avg loss in epoch(incomplete): 0.16644983320384638\n",
      "Epoch: 0 global_step 6450 i 6449 Avg loss in epoch(incomplete): 0.1664451387778733\n",
      "Epoch: 0 global_step 6475 i 6474 Avg loss in epoch(incomplete): 0.16644124171908758\n",
      "saving\n",
      "Epoch: 0 global_step 6500 i 6499 Avg loss in epoch(incomplete): 0.16643620487359853\n",
      "Epoch: 0 global_step 6500 i 6499 Avg loss in epoch(incomplete): 0.16643620487359853\n",
      "Epoch: 0 global_step 6525 i 6524 Avg loss in epoch(incomplete): 0.1664283922828477\n",
      "Epoch: 0 global_step 6550 i 6549 Avg loss in epoch(incomplete): 0.16642280097681147\n",
      "Epoch: 0 global_step 6575 i 6574 Avg loss in epoch(incomplete): 0.16641627092098554\n",
      "Epoch: 0 global_step 6600 i 6599 Avg loss in epoch(incomplete): 0.16641393787933118\n",
      "Epoch: 0 global_step 6625 i 6624 Avg loss in epoch(incomplete): 0.16641150796638346\n",
      "Epoch: 0 global_step 6650 i 6649 Avg loss in epoch(incomplete): 0.1664045308227826\n",
      "Epoch: 0 global_step 6675 i 6674 Avg loss in epoch(incomplete): 0.16639733744248023\n",
      "Epoch: 0 global_step 6700 i 6699 Avg loss in epoch(incomplete): 0.1663939879167436\n",
      "Epoch: 0 global_step 6725 i 6724 Avg loss in epoch(incomplete): 0.16639436247623543\n",
      "saving\n",
      "Epoch: 0 global_step 6750 i 6749 Avg loss in epoch(incomplete): 0.16638683096567788\n",
      "Epoch: 0 global_step 6750 i 6749 Avg loss in epoch(incomplete): 0.16638683096567788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 global_step 6775 i 6774 Avg loss in epoch(incomplete): 0.16638310879798832\n",
      "Epoch: 0 global_step 6800 i 6799 Avg loss in epoch(incomplete): 0.16637879041187903\n",
      "Epoch: 0 global_step 6825 i 6824 Avg loss in epoch(incomplete): 0.16637767775154813\n",
      "Epoch: 0 global_step 6850 i 6849 Avg loss in epoch(incomplete): 0.1663731400026892\n",
      "Epoch: 0 global_step 6875 i 6874 Avg loss in epoch(incomplete): 0.16636250557249244\n",
      "Epoch: 0 global_step 6900 i 6899 Avg loss in epoch(incomplete): 0.16635639325432156\n",
      "Epoch: 0 global_step 6925 i 6924 Avg loss in epoch(incomplete): 0.1663503678438896\n",
      "Epoch: 0 global_step 6950 i 6949 Avg loss in epoch(incomplete): 0.16634522421754522\n",
      "Epoch: 0 global_step 6975 i 6974 Avg loss in epoch(incomplete): 0.16634205773739832\n",
      "saving\n",
      "Epoch: 0 global_step 7000 i 6999 Avg loss in epoch(incomplete): 0.16633602322212288\n",
      "Epoch: 0 global_step 7000 i 6999 Avg loss in epoch(incomplete): 0.16633602322212288\n",
      "Epoch: 0 global_step 7025 i 7024 Avg loss in epoch(incomplete): 0.1663282645003227\n",
      "Epoch: 0 global_step 7050 i 7049 Avg loss in epoch(incomplete): 0.16632036602666192\n",
      "Epoch: 0 global_step 7075 i 7074 Avg loss in epoch(incomplete): 0.16631831442088205\n",
      "Epoch: 0 global_step 7100 i 7099 Avg loss in epoch(incomplete): 0.1663127684908014\n",
      "Epoch: 0 global_step 7125 i 7124 Avg loss in epoch(incomplete): 0.16630997988843083\n",
      "Epoch: 0 global_step 7150 i 7149 Avg loss in epoch(incomplete): 0.16630731089965448\n",
      "Epoch: 0 global_step 7175 i 7174 Avg loss in epoch(incomplete): 0.1663031389572064\n",
      "Epoch: 0 global_step 7200 i 7199 Avg loss in epoch(incomplete): 0.1662964970204565\n",
      "Epoch: 0 global_step 7225 i 7224 Avg loss in epoch(incomplete): 0.1662925609440952\n",
      "saving\n",
      "Epoch: 0 global_step 7250 i 7249 Avg loss in epoch(incomplete): 0.16629167441458537\n",
      "Epoch: 0 global_step 7250 i 7249 Avg loss in epoch(incomplete): 0.16629167441458537\n",
      "Epoch: 0 global_step 7275 i 7274 Avg loss in epoch(incomplete): 0.16628269670755183\n",
      "Epoch: 0 global_step 7300 i 7299 Avg loss in epoch(incomplete): 0.16627976940919276\n",
      "Epoch: 0 global_step 7325 i 7324 Avg loss in epoch(incomplete): 0.1662733746612438\n",
      "Epoch: 0 global_step 7350 i 7349 Avg loss in epoch(incomplete): 0.16626884457408164\n",
      "Epoch: 0 global_step 7375 i 7374 Avg loss in epoch(incomplete): 0.16626753488839682\n",
      "Epoch: 0 global_step 7400 i 7399 Avg loss in epoch(incomplete): 0.16626399846898543\n",
      "Epoch: 0 global_step 7425 i 7424 Avg loss in epoch(incomplete): 0.16625947819213674\n",
      "Epoch: 0 global_step 7450 i 7449 Avg loss in epoch(incomplete): 0.1662581148943645\n",
      "Epoch: 0 global_step 7475 i 7474 Avg loss in epoch(incomplete): 0.16625477872963335\n",
      "saving\n",
      "Epoch: 0 global_step 7500 i 7499 Avg loss in epoch(incomplete): 0.16624996915062268\n",
      "Epoch: 0 global_step 7500 i 7499 Avg loss in epoch(incomplete): 0.16624996915062268\n",
      "Epoch: 0 global_step 7525 i 7524 Avg loss in epoch(incomplete): 0.16624207994866608\n",
      "Epoch: 0 global_step 7550 i 7549 Avg loss in epoch(incomplete): 0.16623291401278895\n",
      "Epoch: 0 global_step 7575 i 7574 Avg loss in epoch(incomplete): 0.16623002196892653\n",
      "Epoch: 0 global_step 7600 i 7599 Avg loss in epoch(incomplete): 0.16622531143458266\n",
      "Epoch: 0 global_step 7625 i 7624 Avg loss in epoch(incomplete): 0.1662225192550753\n",
      "Epoch: 0 global_step 7650 i 7649 Avg loss in epoch(incomplete): 0.16621728489211962\n",
      "Epoch: 0 global_step 7675 i 7674 Avg loss in epoch(incomplete): 0.16621506964927388\n",
      "Epoch: 0 global_step 7700 i 7699 Avg loss in epoch(incomplete): 0.16621556051946307\n",
      "Epoch: 0 global_step 7725 i 7724 Avg loss in epoch(incomplete): 0.16621107392133633\n",
      "saving\n",
      "Epoch: 0 global_step 7750 i 7749 Avg loss in epoch(incomplete): 0.16620323935824055\n",
      "Epoch: 0 global_step 7750 i 7749 Avg loss in epoch(incomplete): 0.16620323935824055\n",
      "Epoch: 0 global_step 7775 i 7774 Avg loss in epoch(incomplete): 0.16619781852726767\n",
      "Epoch: 0 global_step 7800 i 7799 Avg loss in epoch(incomplete): 0.1661944831850437\n",
      "Epoch: 0 global_step 7825 i 7824 Avg loss in epoch(incomplete): 0.16618761491470824\n",
      "Epoch: 0 global_step 7850 i 7849 Avg loss in epoch(incomplete): 0.16618018709929885\n",
      "Epoch: 0 global_step 7875 i 7874 Avg loss in epoch(incomplete): 0.16618016762771304\n",
      "Epoch: 0 global_step 7900 i 7899 Avg loss in epoch(incomplete): 0.16617824405431747\n",
      "Epoch: 0 global_step 7925 i 7924 Avg loss in epoch(incomplete): 0.16617064736995035\n",
      "Epoch: 0 global_step 7950 i 7949 Avg loss in epoch(incomplete): 0.16616928026548722\n",
      "Epoch: 0 global_step 7975 i 7974 Avg loss in epoch(incomplete): 0.1661657424855008\n",
      "saving\n",
      "Epoch: 0 global_step 8000 i 7999 Avg loss in epoch(incomplete): 0.16615948390215635\n",
      "Epoch: 0 global_step 8000 i 7999 Avg loss in epoch(incomplete): 0.16615948390215635\n",
      "Epoch: 0 global_step 8025 i 8024 Avg loss in epoch(incomplete): 0.16615559770867833\n",
      "Epoch: 0 global_step 8050 i 8049 Avg loss in epoch(incomplete): 0.16614814925638044\n",
      "Epoch: 0 global_step 8075 i 8074 Avg loss in epoch(incomplete): 0.16614625889819473\n",
      "Epoch: 0 global_step 8100 i 8099 Avg loss in epoch(incomplete): 0.16614540462692579\n",
      "Epoch: 0 global_step 8125 i 8124 Avg loss in epoch(incomplete): 0.16614071696354793\n",
      "Epoch: 0 global_step 8150 i 8149 Avg loss in epoch(incomplete): 0.1661368752019537\n",
      "Epoch: 0 global_step 8175 i 8174 Avg loss in epoch(incomplete): 0.16613218279424427\n",
      "Epoch: 0 global_step 8200 i 8199 Avg loss in epoch(incomplete): 0.1661263034619936\n",
      "Epoch: 0 global_step 8225 i 8224 Avg loss in epoch(incomplete): 0.1661204811704195\n",
      "saving\n",
      "Epoch: 0 global_step 8250 i 8249 Avg loss in epoch(incomplete): 0.16611257672129257\n",
      "Epoch: 0 global_step 8250 i 8249 Avg loss in epoch(incomplete): 0.16611257672129257\n",
      "Epoch: 0 global_step 8275 i 8274 Avg loss in epoch(incomplete): 0.1661082995226016\n",
      "Epoch: 0 global_step 8300 i 8299 Avg loss in epoch(incomplete): 0.16610547783863114\n",
      "Epoch: 0 global_step 8325 i 8324 Avg loss in epoch(incomplete): 0.166101892305924\n",
      "Epoch: 0 global_step 8350 i 8349 Avg loss in epoch(incomplete): 0.16609999332599298\n",
      "Epoch: 0 global_step 8375 i 8374 Avg loss in epoch(incomplete): 0.16609807024607018\n",
      "Epoch: 0 global_step 8400 i 8399 Avg loss in epoch(incomplete): 0.1660954246723226\n",
      "Epoch: 0 global_step 8425 i 8424 Avg loss in epoch(incomplete): 0.1660893477194387\n",
      "Epoch: 0 global_step 8450 i 8449 Avg loss in epoch(incomplete): 0.16608894691135756\n",
      "Epoch: 0 global_step 8475 i 8474 Avg loss in epoch(incomplete): 0.16608516585686214\n",
      "saving\n",
      "Epoch: 0 global_step 8500 i 8499 Avg loss in epoch(incomplete): 0.16608225793172332\n",
      "Epoch: 0 global_step 8500 i 8499 Avg loss in epoch(incomplete): 0.16608225793172332\n",
      "Epoch: 0 global_step 8525 i 8524 Avg loss in epoch(incomplete): 0.16607993147065564\n",
      "Epoch: 0 global_step 8550 i 8549 Avg loss in epoch(incomplete): 0.16607749332810007\n",
      "Epoch: 0 global_step 8575 i 8574 Avg loss in epoch(incomplete): 0.16607310324472865\n",
      "Epoch: 0 global_step 8600 i 8599 Avg loss in epoch(incomplete): 0.166067730508918\n",
      "Epoch: 0 global_step 8625 i 8624 Avg loss in epoch(incomplete): 0.16606428835530213\n",
      "Epoch: 0 global_step 8650 i 8649 Avg loss in epoch(incomplete): 0.16605962400491528\n",
      "Epoch: 0 global_step 8675 i 8674 Avg loss in epoch(incomplete): 0.16605640209202122\n",
      "saving\n",
      "Epoch: 0 global_step 8695 i 8694 Avg loss in epoch(incomplete): 0.16605317137788397\n",
      "Epoch: 1 global_step 8700 i 4 Avg loss in epoch(incomplete): 0.16621102690696715\n",
      "Epoch: 1 global_step 8725 i 29 Avg loss in epoch(incomplete): 0.16602170914411546\n",
      "saving\n",
      "Epoch: 1 global_step 8750 i 54 Avg loss in epoch(incomplete): 0.1652715184471824\n",
      "Epoch: 1 global_step 8750 i 54 Avg loss in epoch(incomplete): 0.1652715184471824\n",
      "Epoch: 1 global_step 8775 i 79 Avg loss in epoch(incomplete): 0.16499223839491606\n",
      "Epoch: 1 global_step 8800 i 104 Avg loss in epoch(incomplete): 0.16499239092781431\n",
      "Epoch: 1 global_step 8825 i 129 Avg loss in epoch(incomplete): 0.16492704084286322\n",
      "Epoch: 1 global_step 8850 i 154 Avg loss in epoch(incomplete): 0.1648650018438216\n",
      "Epoch: 1 global_step 8875 i 179 Avg loss in epoch(incomplete): 0.16491949897673394\n",
      "Epoch: 1 global_step 8900 i 204 Avg loss in epoch(incomplete): 0.16491854641495682\n",
      "Epoch: 1 global_step 8925 i 229 Avg loss in epoch(incomplete): 0.1648678961655368\n",
      "Epoch: 1 global_step 8950 i 254 Avg loss in epoch(incomplete): 0.16491110494323805\n",
      "Epoch: 1 global_step 8975 i 279 Avg loss in epoch(incomplete): 0.16488778851926328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n",
      "Epoch: 1 global_step 9000 i 304 Avg loss in epoch(incomplete): 0.16490839597631674\n",
      "Epoch: 1 global_step 9000 i 304 Avg loss in epoch(incomplete): 0.16490839597631674\n",
      "Epoch: 1 global_step 9025 i 329 Avg loss in epoch(incomplete): 0.16489045895410306\n",
      "Epoch: 1 global_step 9050 i 354 Avg loss in epoch(incomplete): 0.1648878014843229\n",
      "Epoch: 1 global_step 9075 i 379 Avg loss in epoch(incomplete): 0.16489398004977326\n",
      "Epoch: 1 global_step 9100 i 404 Avg loss in epoch(incomplete): 0.16488549337710864\n",
      "Epoch: 1 global_step 9125 i 429 Avg loss in epoch(incomplete): 0.16489418024240537\n",
      "Epoch: 1 global_step 9150 i 454 Avg loss in epoch(incomplete): 0.16488261615837013\n",
      "Epoch: 1 global_step 9175 i 479 Avg loss in epoch(incomplete): 0.16495385880892474\n",
      "Epoch: 1 global_step 9200 i 504 Avg loss in epoch(incomplete): 0.1649645954075426\n",
      "Epoch: 1 global_step 9225 i 529 Avg loss in epoch(incomplete): 0.1649880033337845\n",
      "saving\n",
      "Epoch: 1 global_step 9250 i 554 Avg loss in epoch(incomplete): 0.1649769325245608\n",
      "Epoch: 1 global_step 9250 i 554 Avg loss in epoch(incomplete): 0.1649769325245608\n",
      "Epoch: 1 global_step 9275 i 579 Avg loss in epoch(incomplete): 0.16495041271735883\n",
      "Epoch: 1 global_step 9300 i 604 Avg loss in epoch(incomplete): 0.16496549940798894\n",
      "Epoch: 1 global_step 9325 i 629 Avg loss in epoch(incomplete): 0.16493815954715488\n",
      "Epoch: 1 global_step 9350 i 654 Avg loss in epoch(incomplete): 0.16494685880100454\n",
      "Epoch: 1 global_step 9375 i 679 Avg loss in epoch(incomplete): 0.16493881640627103\n",
      "Epoch: 1 global_step 9400 i 704 Avg loss in epoch(incomplete): 0.16495726078960066\n",
      "Epoch: 1 global_step 9425 i 729 Avg loss in epoch(incomplete): 0.16497259983052945\n",
      "Epoch: 1 global_step 9450 i 754 Avg loss in epoch(incomplete): 0.16497963400471288\n",
      "Epoch: 1 global_step 9475 i 779 Avg loss in epoch(incomplete): 0.16496419195945447\n",
      "saving\n",
      "Epoch: 1 global_step 9500 i 804 Avg loss in epoch(incomplete): 0.1649861112144423\n",
      "Epoch: 1 global_step 9500 i 804 Avg loss in epoch(incomplete): 0.1649861112144423\n",
      "Epoch: 1 global_step 9525 i 829 Avg loss in epoch(incomplete): 0.16498614768665956\n",
      "Epoch: 1 global_step 9550 i 854 Avg loss in epoch(incomplete): 0.16498832911775824\n",
      "Epoch: 1 global_step 9575 i 879 Avg loss in epoch(incomplete): 0.16498666947538201\n",
      "Epoch: 1 global_step 9600 i 904 Avg loss in epoch(incomplete): 0.16500343411996218\n",
      "Epoch: 1 global_step 9625 i 929 Avg loss in epoch(incomplete): 0.16503591367634393\n",
      "Epoch: 1 global_step 9650 i 954 Avg loss in epoch(incomplete): 0.16502403961738366\n",
      "Epoch: 1 global_step 9675 i 979 Avg loss in epoch(incomplete): 0.1650202591352317\n",
      "Epoch: 1 global_step 9700 i 1004 Avg loss in epoch(incomplete): 0.16502654364156485\n",
      "Epoch: 1 global_step 9725 i 1029 Avg loss in epoch(incomplete): 0.16503357286881476\n",
      "saving\n",
      "Epoch: 1 global_step 9750 i 1054 Avg loss in epoch(incomplete): 0.16505264122904195\n",
      "Epoch: 1 global_step 9750 i 1054 Avg loss in epoch(incomplete): 0.16505264122904195\n",
      "Epoch: 1 global_step 9775 i 1079 Avg loss in epoch(incomplete): 0.16503840152312207\n",
      "Epoch: 1 global_step 9800 i 1104 Avg loss in epoch(incomplete): 0.16503140778023734\n",
      "Epoch: 1 global_step 9825 i 1129 Avg loss in epoch(incomplete): 0.16501604954225826\n",
      "Epoch: 1 global_step 9850 i 1154 Avg loss in epoch(incomplete): 0.16501698674577656\n",
      "Epoch: 1 global_step 9875 i 1179 Avg loss in epoch(incomplete): 0.16503822960085787\n",
      "Epoch: 1 global_step 9900 i 1204 Avg loss in epoch(incomplete): 0.1650486656244365\n",
      "Epoch: 1 global_step 9925 i 1229 Avg loss in epoch(incomplete): 0.16504009727055463\n",
      "Epoch: 1 global_step 9950 i 1254 Avg loss in epoch(incomplete): 0.16502507337298528\n",
      "Epoch: 1 global_step 9975 i 1279 Avg loss in epoch(incomplete): 0.16502905841916798\n",
      "saving\n",
      "Epoch: 1 global_step 10000 i 1304 Avg loss in epoch(incomplete): 0.16500882992799254\n",
      "Epoch: 1 global_step 10000 i 1304 Avg loss in epoch(incomplete): 0.16500882992799254\n",
      "Epoch: 1 global_step 10025 i 1329 Avg loss in epoch(incomplete): 0.16501960803691607\n",
      "Epoch: 1 global_step 10050 i 1354 Avg loss in epoch(incomplete): 0.16501777868209289\n",
      "Epoch: 1 global_step 10075 i 1379 Avg loss in epoch(incomplete): 0.16501312517169592\n",
      "Epoch: 1 global_step 10100 i 1404 Avg loss in epoch(incomplete): 0.1650088046157063\n",
      "Epoch: 1 global_step 10125 i 1429 Avg loss in epoch(incomplete): 0.1649980167825739\n",
      "Epoch: 1 global_step 10150 i 1454 Avg loss in epoch(incomplete): 0.1650039574841863\n",
      "Epoch: 1 global_step 10175 i 1479 Avg loss in epoch(incomplete): 0.1650038527677188\n",
      "Epoch: 1 global_step 10200 i 1504 Avg loss in epoch(incomplete): 0.1650267908442456\n",
      "Epoch: 1 global_step 10225 i 1529 Avg loss in epoch(incomplete): 0.16502376229934443\n",
      "saving\n",
      "Epoch: 1 global_step 10250 i 1554 Avg loss in epoch(incomplete): 0.16503434340286868\n",
      "Epoch: 1 global_step 10250 i 1554 Avg loss in epoch(incomplete): 0.16503434340286868\n",
      "Epoch: 1 global_step 10275 i 1579 Avg loss in epoch(incomplete): 0.16500692138377623\n",
      "Epoch: 1 global_step 10300 i 1604 Avg loss in epoch(incomplete): 0.16500306354133512\n",
      "Epoch: 1 global_step 10325 i 1629 Avg loss in epoch(incomplete): 0.16499840614437325\n",
      "Epoch: 1 global_step 10350 i 1654 Avg loss in epoch(incomplete): 0.1650091649902551\n",
      "Epoch: 1 global_step 10375 i 1679 Avg loss in epoch(incomplete): 0.16500638936247145\n",
      "Epoch: 1 global_step 10400 i 1704 Avg loss in epoch(incomplete): 0.16501782965625136\n",
      "Epoch: 1 global_step 10425 i 1729 Avg loss in epoch(incomplete): 0.16501838456344053\n",
      "Epoch: 1 global_step 10450 i 1754 Avg loss in epoch(incomplete): 0.16502106157463162\n",
      "Epoch: 1 global_step 10475 i 1779 Avg loss in epoch(incomplete): 0.16501535946566068\n",
      "saving\n",
      "Epoch: 1 global_step 10500 i 1804 Avg loss in epoch(incomplete): 0.16501096975770355\n",
      "Epoch: 1 global_step 10500 i 1804 Avg loss in epoch(incomplete): 0.16501096975770355\n",
      "Epoch: 1 global_step 10525 i 1829 Avg loss in epoch(incomplete): 0.16502668912130627\n",
      "Epoch: 1 global_step 10550 i 1854 Avg loss in epoch(incomplete): 0.16502175964917135\n",
      "Epoch: 1 global_step 10575 i 1879 Avg loss in epoch(incomplete): 0.165031340488411\n",
      "Epoch: 1 global_step 10600 i 1904 Avg loss in epoch(incomplete): 0.1650179815730398\n",
      "Epoch: 1 global_step 10625 i 1929 Avg loss in epoch(incomplete): 0.16502510823425234\n",
      "Epoch: 1 global_step 10650 i 1954 Avg loss in epoch(incomplete): 0.16502879502065956\n",
      "Epoch: 1 global_step 10675 i 1979 Avg loss in epoch(incomplete): 0.16504257492194271\n",
      "Epoch: 1 global_step 10700 i 2004 Avg loss in epoch(incomplete): 0.1650332622917513\n",
      "Epoch: 1 global_step 10725 i 2029 Avg loss in epoch(incomplete): 0.1650200102496617\n",
      "saving\n",
      "Epoch: 1 global_step 10750 i 2054 Avg loss in epoch(incomplete): 0.16502269520231697\n",
      "Epoch: 1 global_step 10750 i 2054 Avg loss in epoch(incomplete): 0.16502269520231697\n",
      "Epoch: 1 global_step 10775 i 2079 Avg loss in epoch(incomplete): 0.16500989403575658\n",
      "Epoch: 1 global_step 10800 i 2104 Avg loss in epoch(incomplete): 0.16500999833370897\n",
      "Epoch: 1 global_step 10825 i 2129 Avg loss in epoch(incomplete): 0.16500873729376725\n",
      "Epoch: 1 global_step 10850 i 2154 Avg loss in epoch(incomplete): 0.16501078348425313\n",
      "Epoch: 1 global_step 10875 i 2179 Avg loss in epoch(incomplete): 0.16501812127615334\n",
      "Epoch: 1 global_step 10900 i 2204 Avg loss in epoch(incomplete): 0.16501022037329857\n",
      "Epoch: 1 global_step 10925 i 2229 Avg loss in epoch(incomplete): 0.16501577669595924\n",
      "Epoch: 1 global_step 10950 i 2254 Avg loss in epoch(incomplete): 0.1650114409476849\n",
      "Epoch: 1 global_step 10975 i 2279 Avg loss in epoch(incomplete): 0.16501130839450318\n",
      "saving\n",
      "Epoch: 1 global_step 11000 i 2304 Avg loss in epoch(incomplete): 0.16501757702315448\n",
      "Epoch: 1 global_step 11000 i 2304 Avg loss in epoch(incomplete): 0.16501757702315448\n",
      "Epoch: 1 global_step 11025 i 2329 Avg loss in epoch(incomplete): 0.1650180431266711\n",
      "Epoch: 1 global_step 11050 i 2354 Avg loss in epoch(incomplete): 0.1650203064305514\n",
      "Epoch: 1 global_step 11075 i 2379 Avg loss in epoch(incomplete): 0.1650227998672914\n",
      "Epoch: 1 global_step 11100 i 2404 Avg loss in epoch(incomplete): 0.16503507777459903\n",
      "Epoch: 1 global_step 11125 i 2429 Avg loss in epoch(incomplete): 0.16503535491939436\n",
      "Epoch: 1 global_step 11150 i 2454 Avg loss in epoch(incomplete): 0.16502998925275084\n",
      "Epoch: 1 global_step 11175 i 2479 Avg loss in epoch(incomplete): 0.1650233287664671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 global_step 11200 i 2504 Avg loss in epoch(incomplete): 0.16501445487706723\n",
      "Epoch: 1 global_step 11225 i 2529 Avg loss in epoch(incomplete): 0.1650170661185099\n",
      "saving\n",
      "Epoch: 1 global_step 11250 i 2554 Avg loss in epoch(incomplete): 0.16501362928555668\n",
      "Epoch: 1 global_step 11250 i 2554 Avg loss in epoch(incomplete): 0.16501362928555668\n",
      "Epoch: 1 global_step 11275 i 2579 Avg loss in epoch(incomplete): 0.16501448911636374\n",
      "Epoch: 1 global_step 11300 i 2604 Avg loss in epoch(incomplete): 0.16501045375776383\n",
      "Epoch: 1 global_step 11325 i 2629 Avg loss in epoch(incomplete): 0.16501539773360857\n",
      "Epoch: 1 global_step 11350 i 2654 Avg loss in epoch(incomplete): 0.16502244022943205\n",
      "Epoch: 1 global_step 11375 i 2679 Avg loss in epoch(incomplete): 0.16503372137337477\n",
      "Epoch: 1 global_step 11400 i 2704 Avg loss in epoch(incomplete): 0.1650333434122988\n",
      "Epoch: 1 global_step 11425 i 2729 Avg loss in epoch(incomplete): 0.16504125969532207\n",
      "Epoch: 1 global_step 11450 i 2754 Avg loss in epoch(incomplete): 0.16503325266976537\n",
      "Epoch: 1 global_step 11475 i 2779 Avg loss in epoch(incomplete): 0.16503025555996587\n",
      "saving\n",
      "Epoch: 1 global_step 11500 i 2804 Avg loss in epoch(incomplete): 0.16503825413989512\n",
      "Epoch: 1 global_step 11500 i 2804 Avg loss in epoch(incomplete): 0.16503825413989512\n",
      "Epoch: 1 global_step 11525 i 2829 Avg loss in epoch(incomplete): 0.16504287007314156\n",
      "Epoch: 1 global_step 11550 i 2854 Avg loss in epoch(incomplete): 0.16503420998252627\n",
      "Epoch: 1 global_step 11575 i 2879 Avg loss in epoch(incomplete): 0.1650242437246359\n",
      "Epoch: 1 global_step 11600 i 2904 Avg loss in epoch(incomplete): 0.16501934796110077\n",
      "Epoch: 1 global_step 11625 i 2929 Avg loss in epoch(incomplete): 0.16501966040492463\n",
      "Epoch: 1 global_step 11650 i 2954 Avg loss in epoch(incomplete): 0.1650298157873896\n",
      "Epoch: 1 global_step 11675 i 2979 Avg loss in epoch(incomplete): 0.16502897999430663\n",
      "Epoch: 1 global_step 11700 i 3004 Avg loss in epoch(incomplete): 0.16503596639573673\n",
      "Epoch: 1 global_step 11725 i 3029 Avg loss in epoch(incomplete): 0.16502428029728408\n",
      "saving\n",
      "Epoch: 1 global_step 11750 i 3054 Avg loss in epoch(incomplete): 0.16502569537798822\n",
      "Epoch: 1 global_step 11750 i 3054 Avg loss in epoch(incomplete): 0.16502569537798822\n",
      "Epoch: 1 global_step 11775 i 3079 Avg loss in epoch(incomplete): 0.1650285416367379\n",
      "Epoch: 1 global_step 11800 i 3104 Avg loss in epoch(incomplete): 0.16503518561618147\n",
      "Epoch: 1 global_step 11825 i 3129 Avg loss in epoch(incomplete): 0.1650353089879496\n",
      "Epoch: 1 global_step 11850 i 3154 Avg loss in epoch(incomplete): 0.16503318956744653\n",
      "Epoch: 1 global_step 11875 i 3179 Avg loss in epoch(incomplete): 0.1650290292576424\n",
      "Epoch: 1 global_step 11900 i 3204 Avg loss in epoch(incomplete): 0.165023211072462\n",
      "Epoch: 1 global_step 11925 i 3229 Avg loss in epoch(incomplete): 0.16502219205116708\n",
      "Epoch: 1 global_step 11950 i 3254 Avg loss in epoch(incomplete): 0.16502167909833876\n",
      "Epoch: 1 global_step 11975 i 3279 Avg loss in epoch(incomplete): 0.16502725350238928\n",
      "saving\n",
      "Epoch: 1 global_step 12000 i 3304 Avg loss in epoch(incomplete): 0.16502793520553752\n",
      "Epoch: 1 global_step 12000 i 3304 Avg loss in epoch(incomplete): 0.16502793520553752\n",
      "Epoch: 1 global_step 12025 i 3329 Avg loss in epoch(incomplete): 0.16503035533535587\n",
      "Epoch: 1 global_step 12050 i 3354 Avg loss in epoch(incomplete): 0.16503376079120863\n",
      "Epoch: 1 global_step 12075 i 3379 Avg loss in epoch(incomplete): 0.1650398128175524\n",
      "Epoch: 1 global_step 12100 i 3404 Avg loss in epoch(incomplete): 0.16503991575230587\n",
      "Epoch: 1 global_step 12125 i 3429 Avg loss in epoch(incomplete): 0.16504572742447562\n",
      "Epoch: 1 global_step 12150 i 3454 Avg loss in epoch(incomplete): 0.16504779819900497\n",
      "Epoch: 1 global_step 12175 i 3479 Avg loss in epoch(incomplete): 0.1650406597075106\n",
      "Epoch: 1 global_step 12200 i 3504 Avg loss in epoch(incomplete): 0.16504163251878873\n",
      "Epoch: 1 global_step 12225 i 3529 Avg loss in epoch(incomplete): 0.16503707533939702\n",
      "saving\n",
      "Epoch: 1 global_step 12250 i 3554 Avg loss in epoch(incomplete): 0.16504114125599842\n",
      "Epoch: 1 global_step 12250 i 3554 Avg loss in epoch(incomplete): 0.16504114125599842\n",
      "Epoch: 1 global_step 12275 i 3579 Avg loss in epoch(incomplete): 0.16503561229013197\n",
      "Epoch: 1 global_step 12300 i 3604 Avg loss in epoch(incomplete): 0.16503068634028573\n",
      "Epoch: 1 global_step 12325 i 3629 Avg loss in epoch(incomplete): 0.1650333598174011\n",
      "Epoch: 1 global_step 12350 i 3654 Avg loss in epoch(incomplete): 0.16503420840291416\n",
      "Epoch: 1 global_step 12375 i 3679 Avg loss in epoch(incomplete): 0.1650393599158396\n",
      "Epoch: 1 global_step 12400 i 3704 Avg loss in epoch(incomplete): 0.1650431917666102\n",
      "Epoch: 1 global_step 12425 i 3729 Avg loss in epoch(incomplete): 0.16504187704171316\n",
      "Epoch: 1 global_step 12450 i 3754 Avg loss in epoch(incomplete): 0.1650474333136123\n",
      "Epoch: 1 global_step 12475 i 3779 Avg loss in epoch(incomplete): 0.1650483175520859\n",
      "saving\n",
      "Epoch: 1 global_step 12500 i 3804 Avg loss in epoch(incomplete): 0.16505045801127005\n",
      "Epoch: 1 global_step 12500 i 3804 Avg loss in epoch(incomplete): 0.16505045801127005\n",
      "Epoch: 1 global_step 12525 i 3829 Avg loss in epoch(incomplete): 0.1650498220643549\n",
      "Epoch: 1 global_step 12550 i 3854 Avg loss in epoch(incomplete): 0.16504145826269834\n",
      "Epoch: 1 global_step 12575 i 3879 Avg loss in epoch(incomplete): 0.1650401375842156\n",
      "Epoch: 1 global_step 12600 i 3904 Avg loss in epoch(incomplete): 0.16504735434177437\n",
      "Epoch: 1 global_step 12625 i 3929 Avg loss in epoch(incomplete): 0.1650427339186195\n",
      "Epoch: 1 global_step 12650 i 3954 Avg loss in epoch(incomplete): 0.16504508238073848\n",
      "Epoch: 1 global_step 12675 i 3979 Avg loss in epoch(incomplete): 0.16504401214907516\n",
      "Epoch: 1 global_step 12700 i 4004 Avg loss in epoch(incomplete): 0.16504909569181306\n",
      "Epoch: 1 global_step 12725 i 4029 Avg loss in epoch(incomplete): 0.16504560708260121\n",
      "saving\n",
      "Epoch: 1 global_step 12750 i 4054 Avg loss in epoch(incomplete): 0.16504423311841473\n",
      "Epoch: 1 global_step 12750 i 4054 Avg loss in epoch(incomplete): 0.16504423311841473\n",
      "Epoch: 1 global_step 12775 i 4079 Avg loss in epoch(incomplete): 0.16504295620629017\n",
      "Epoch: 1 global_step 12800 i 4104 Avg loss in epoch(incomplete): 0.16503554901673065\n",
      "Epoch: 1 global_step 12825 i 4129 Avg loss in epoch(incomplete): 0.16503529839452186\n",
      "Epoch: 1 global_step 12850 i 4154 Avg loss in epoch(incomplete): 0.16503961873829148\n",
      "Epoch: 1 global_step 12875 i 4179 Avg loss in epoch(incomplete): 0.16503681191844805\n",
      "Epoch: 1 global_step 12900 i 4204 Avg loss in epoch(incomplete): 0.16504307355948775\n",
      "Epoch: 1 global_step 12925 i 4229 Avg loss in epoch(incomplete): 0.1650443780365847\n",
      "Epoch: 1 global_step 12950 i 4254 Avg loss in epoch(incomplete): 0.1650432971368525\n",
      "Epoch: 1 global_step 12975 i 4279 Avg loss in epoch(incomplete): 0.16503681097284098\n",
      "saving\n",
      "Epoch: 1 global_step 13000 i 4304 Avg loss in epoch(incomplete): 0.1650409331651238\n",
      "Epoch: 1 global_step 13000 i 4304 Avg loss in epoch(incomplete): 0.1650409331651238\n",
      "Epoch: 1 global_step 13025 i 4329 Avg loss in epoch(incomplete): 0.16504674073454964\n",
      "Epoch: 1 global_step 13050 i 4354 Avg loss in epoch(incomplete): 0.16504280012866523\n",
      "Epoch: 1 global_step 13075 i 4379 Avg loss in epoch(incomplete): 0.16504192873495355\n",
      "Epoch: 1 global_step 13100 i 4404 Avg loss in epoch(incomplete): 0.16504243319002102\n",
      "Epoch: 1 global_step 13125 i 4429 Avg loss in epoch(incomplete): 0.16504123513303007\n",
      "Epoch: 1 global_step 13150 i 4454 Avg loss in epoch(incomplete): 0.16504380913361422\n",
      "Epoch: 1 global_step 13175 i 4479 Avg loss in epoch(incomplete): 0.16503835846669973\n",
      "Epoch: 1 global_step 13200 i 4504 Avg loss in epoch(incomplete): 0.16504050611986568\n",
      "Epoch: 1 global_step 13225 i 4529 Avg loss in epoch(incomplete): 0.16504254243429134\n",
      "saving\n",
      "Epoch: 1 global_step 13250 i 4554 Avg loss in epoch(incomplete): 0.16504793681703206\n",
      "Epoch: 1 global_step 13250 i 4554 Avg loss in epoch(incomplete): 0.16504793681703206\n",
      "Epoch: 1 global_step 13275 i 4579 Avg loss in epoch(incomplete): 0.16504843591927962\n",
      "Epoch: 1 global_step 13300 i 4604 Avg loss in epoch(incomplete): 0.1650518857824427\n",
      "Epoch: 1 global_step 13325 i 4629 Avg loss in epoch(incomplete): 0.16505398717477562\n",
      "Epoch: 1 global_step 13350 i 4654 Avg loss in epoch(incomplete): 0.16505448380615223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 global_step 13375 i 4679 Avg loss in epoch(incomplete): 0.16505373880330823\n",
      "Epoch: 1 global_step 13400 i 4704 Avg loss in epoch(incomplete): 0.1650517250855595\n",
      "Epoch: 1 global_step 13425 i 4729 Avg loss in epoch(incomplete): 0.16505058107240003\n",
      "Epoch: 1 global_step 13450 i 4754 Avg loss in epoch(incomplete): 0.16505191878314776\n",
      "Epoch: 1 global_step 13475 i 4779 Avg loss in epoch(incomplete): 0.16504927843684433\n",
      "saving\n",
      "Epoch: 1 global_step 13500 i 4804 Avg loss in epoch(incomplete): 0.16504900062865696\n",
      "Epoch: 1 global_step 13500 i 4804 Avg loss in epoch(incomplete): 0.16504900062865696\n",
      "Epoch: 1 global_step 13525 i 4829 Avg loss in epoch(incomplete): 0.16504768852614962\n",
      "Epoch: 1 global_step 13550 i 4854 Avg loss in epoch(incomplete): 0.16505155555067544\n",
      "Epoch: 1 global_step 13575 i 4879 Avg loss in epoch(incomplete): 0.1650588305361691\n",
      "Epoch: 1 global_step 13600 i 4904 Avg loss in epoch(incomplete): 0.16506337573282823\n",
      "Epoch: 1 global_step 13625 i 4929 Avg loss in epoch(incomplete): 0.16506478139945507\n",
      "Epoch: 1 global_step 13650 i 4954 Avg loss in epoch(incomplete): 0.16506655487776042\n",
      "Epoch: 1 global_step 13675 i 4979 Avg loss in epoch(incomplete): 0.16506583786094522\n",
      "Epoch: 1 global_step 13700 i 5004 Avg loss in epoch(incomplete): 0.16506741369639957\n",
      "Epoch: 1 global_step 13725 i 5029 Avg loss in epoch(incomplete): 0.16506787617922303\n",
      "saving\n",
      "Epoch: 1 global_step 13750 i 5054 Avg loss in epoch(incomplete): 0.16506766096774478\n",
      "Epoch: 1 global_step 13750 i 5054 Avg loss in epoch(incomplete): 0.16506766096774478\n",
      "Epoch: 1 global_step 13775 i 5079 Avg loss in epoch(incomplete): 0.16506942690122783\n",
      "Epoch: 1 global_step 13800 i 5104 Avg loss in epoch(incomplete): 0.16506249722199154\n",
      "Epoch: 1 global_step 13825 i 5129 Avg loss in epoch(incomplete): 0.16506595736474786\n",
      "Epoch: 1 global_step 13850 i 5154 Avg loss in epoch(incomplete): 0.16505741401856439\n",
      "Epoch: 1 global_step 13875 i 5179 Avg loss in epoch(incomplete): 0.1650554929662165\n",
      "Epoch: 1 global_step 13900 i 5204 Avg loss in epoch(incomplete): 0.16505858016403446\n",
      "Epoch: 1 global_step 13925 i 5229 Avg loss in epoch(incomplete): 0.16505424050653414\n",
      "Epoch: 1 global_step 13950 i 5254 Avg loss in epoch(incomplete): 0.1650486416299495\n",
      "Epoch: 1 global_step 13975 i 5279 Avg loss in epoch(incomplete): 0.16504962844491908\n",
      "saving\n",
      "Epoch: 1 global_step 14000 i 5304 Avg loss in epoch(incomplete): 0.16505160971029428\n",
      "Epoch: 1 global_step 14000 i 5304 Avg loss in epoch(incomplete): 0.16505160971029428\n",
      "Epoch: 1 global_step 14025 i 5329 Avg loss in epoch(incomplete): 0.16505779365940793\n",
      "Epoch: 1 global_step 14050 i 5354 Avg loss in epoch(incomplete): 0.16505919196247276\n",
      "Epoch: 1 global_step 14075 i 5379 Avg loss in epoch(incomplete): 0.16505618478451964\n",
      "Epoch: 1 global_step 14100 i 5404 Avg loss in epoch(incomplete): 0.1650564538754323\n",
      "Epoch: 1 global_step 14125 i 5429 Avg loss in epoch(incomplete): 0.16505521582250876\n",
      "Epoch: 1 global_step 14150 i 5454 Avg loss in epoch(incomplete): 0.1650534593818605\n",
      "Epoch: 1 global_step 14175 i 5479 Avg loss in epoch(incomplete): 0.16505135956363087\n"
     ]
    }
   ],
   "source": [
    "if tf.gfile.Exists('log/' + modelname):\n",
    "   tf.gfile.DeleteRecursively('log/' + modelname) \n",
    "\n",
    "# train\n",
    "\n",
    "print_every = 25\n",
    "save_every = 250\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    if global_step_to_load is None:\n",
    "        global_step = 0\n",
    "    else:\n",
    "        saver.restore(sess, 'log/%s-%d' % (modelname, global_step_to_load))\n",
    "        global_step = global_step_to_load\n",
    "    \n",
    "#    print(layer)\n",
    "    \n",
    "    writer = tf.summary.FileWriter('log/' + modelname + '/train', sess.graph)\n",
    "    writerv = tf.summary.FileWriter('log/' + modelname + '/valid')\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    if global_step_to_load is None:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for i in range(num_batches_in_train):\n",
    "            batch_X, batch_Y = sess.run([seq_batch, label_batch])\n",
    "            batch_Xv, batch_Yv = sess.run([seqv_batch, labelv_batch])\n",
    "            _, _loss = sess.run([update, loss],\n",
    "                            feed_dict={X: batch_X, Y: batch_Y})\n",
    "            total_loss += _loss #/ num_batches_in_train\n",
    "            \n",
    "            summary = sess.run(summary_op, feed_dict={X: batch_X,\n",
    "                                                    Y: batch_Y})\n",
    "            summaryv = sess.run(summary_op, feed_dict={X: batch_Xv,\n",
    "                                                    Y: batch_Yv})\n",
    "#            writer.add_summary(summary, global_step=epoch*num_batches_in_train + i)\n",
    "#            writerv.add_summary(summaryv, global_step=epoch*num_batches_in_train + i)\n",
    "            writer.add_summary(summary, global_step=global_step)\n",
    "            writerv.add_summary(summaryv, global_step=global_step)\n",
    "            \n",
    "            global_step += 1\n",
    "            \n",
    "            if global_step % save_every == 0:\n",
    "                print('saving')\n",
    "                print('Epoch:',epoch,'global_step',global_step,'i',i,'Avg loss in epoch(incomplete):',total_loss / (i+1))\n",
    "                saver.save(sess, 'log/%s' % modelname, global_step=global_step)\n",
    "                \n",
    "            if global_step % print_every == 0:\n",
    "                print('Epoch:',epoch,'global_step',global_step,'i',i,'Avg loss in epoch(incomplete):',total_loss / (i+1))\n",
    "        \n",
    "        print('saving')\n",
    "        print('Epoch:',epoch,'global_step',global_step,'i',i,'Avg loss in epoch(incomplete):',total_loss / (i+1))\n",
    "\n",
    "        saver.save(sess, 'log/%s' % modelname, global_step=global_step)\n",
    "    \n",
    "    writer.close()\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
