{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "import pdb\n",
    "import fxns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data locations\n",
    "raw_data_path = '../data/shuffled_examples'\n",
    "outbase = '../output/shuffled_examples'\n",
    "train_out_path = '%s/texttrain' % outbase\n",
    "valid_out_path = '%s/textvalidate' % outbase\n",
    "test_out_path = '%s/texttest' % outbase\n",
    "motif_path = '%s/../motifs' % raw_data_path\n",
    "\n",
    "# training hyperparameters\n",
    "batch_size = 50\n",
    "num_batches_in_train = int(434786 / batch_size)\n",
    "num_epochs = 2\n",
    "capacity = 2000\n",
    "min_after_dequeue = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# retrieving models\n",
    "global_step_to_load = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs are of size 4000\n",
      "outputs are of size 24\n",
      "../output/shuffled_examples/texttest\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# get training data\n",
    "(seq, label), info = fxns.get_seq_and_label(train_out_path)\n",
    "seq_batch, label_batch = tf.train.shuffle_batch([seq, label],\n",
    "    batch_size=batch_size,\n",
    "    capacity=capacity,\n",
    "    min_after_dequeue=min_after_dequeue)\n",
    "print('inputs are of size', info['seq_len'])\n",
    "\n",
    "# get validation data\n",
    "(seqv, labelv), infov = fxns.get_seq_and_label(valid_out_path)\n",
    "seqv_batch, labelv_batch = tf.train.shuffle_batch([seqv, labelv],\n",
    "    batch_size=batch_size,\n",
    "    capacity=capacity,\n",
    "    min_after_dequeue=min_after_dequeue)\n",
    "print('outputs are of size', info['label_len'])\n",
    "\n",
    "reload(fxns)\n",
    "print(test_out_path)\n",
    "(seqt, labelt), info = fxns.get_seq_and_label(test_out_path, num_epochs=None)\n",
    "seqt_batch, labelt_batch = tf.train.shuffle_batch([seqt, labelt],\n",
    "    batch_size=batch_size,\n",
    "    capacity=capacity,\n",
    "    min_after_dequeue=min_after_dequeue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('max filter length set to', 21)\n",
      "500.0\n",
      "250.0\n",
      "125.0\n",
      "4000 h 15 125.0\n"
     ]
    }
   ],
   "source": [
    "# # get model -- logistic\n",
    "# import logreg_model\n",
    "# modelname='logreg'\n",
    "# X, Y, loss, logits = logreg_model.get_logreg_model(info['seq_len'], info['label_len'])\n",
    "\n",
    "# get model -- generic convnet\n",
    "import motif_model; reload(motif_model)\n",
    "filters = motif_model.get_motifs(motif_path)\n",
    "modelname='motifconv'\n",
    "#conv_infos = [(7,(1,20),(2,2),4),(5,(1,20),(2,2),7)]#, (8,(1,20),(2,2),5)]\n",
    "conv_infos = [(14,(1,21),(2,2),2,4),(14,(1,8),(2,2),2,14),(7,(1,5),(2,2),2,14)]#, (8,(1,20),(2,2),5)]\n",
    "X, Y, loss, logits = motif_model.get_motif_model(info['seq_len'], info['label_len'], conv_infos, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate,\n",
    "                                                 name='SGD-Optimizer')\n",
    "    update = optimizer.minimize(loss)\n",
    "\n",
    "# define other summaries we want\n",
    "with tf.name_scope('summaries'):\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.histogram('histogram-loss', loss)\n",
    "    summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 global_step 25 i 24 Avg loss in epoch(incomplete): 0.76439155817\n",
      "Epoch: 0 global_step 50 i 49 Avg loss in epoch(incomplete): 0.744075440168\n",
      "Epoch: 0 global_step 75 i 74 Avg loss in epoch(incomplete): 0.726037234465\n",
      "Epoch: 0 global_step 100 i 99 Avg loss in epoch(incomplete): 0.709554651976\n",
      "Epoch: 0 global_step 125 i 124 Avg loss in epoch(incomplete): 0.693957925797\n",
      "Epoch: 0 global_step 150 i 149 Avg loss in epoch(incomplete): 0.678978453875\n",
      "Epoch: 0 global_step 175 i 174 Avg loss in epoch(incomplete): 0.664363247326\n",
      "Epoch: 0 global_step 200 i 199 Avg loss in epoch(incomplete): 0.649966078401\n",
      "Epoch: 0 global_step 225 i 224 Avg loss in epoch(incomplete): 0.635458083683\n",
      "saving\n",
      "Epoch: 0 global_step 250 i 249 Avg loss in epoch(incomplete): 0.621021033049\n",
      "Epoch: 0 global_step 250 i 249 Avg loss in epoch(incomplete): 0.621021033049\n",
      "Epoch: 0 global_step 275 i 274 Avg loss in epoch(incomplete): 0.606645810279\n",
      "Epoch: 0 global_step 300 i 299 Avg loss in epoch(incomplete): 0.59226319174\n",
      "Epoch: 0 global_step 325 i 324 Avg loss in epoch(incomplete): 0.577922452046\n",
      "Epoch: 0 global_step 350 i 349 Avg loss in epoch(incomplete): 0.56367823158\n",
      "Epoch: 0 global_step 375 i 374 Avg loss in epoch(incomplete): 0.54964082098\n",
      "Epoch: 0 global_step 400 i 399 Avg loss in epoch(incomplete): 0.535980809554\n",
      "Epoch: 0 global_step 425 i 424 Avg loss in epoch(incomplete): 0.522617515185\n",
      "Epoch: 0 global_step 450 i 449 Avg loss in epoch(incomplete): 0.509711384442\n",
      "Epoch: 0 global_step 475 i 474 Avg loss in epoch(incomplete): 0.49727762147\n",
      "saving\n",
      "Epoch: 0 global_step 500 i 499 Avg loss in epoch(incomplete): 0.485353512913\n",
      "Epoch: 0 global_step 500 i 499 Avg loss in epoch(incomplete): 0.485353512913\n",
      "Epoch: 0 global_step 525 i 524 Avg loss in epoch(incomplete): 0.473928255496\n",
      "Epoch: 0 global_step 550 i 549 Avg loss in epoch(incomplete): 0.463042864068\n",
      "Epoch: 0 global_step 575 i 574 Avg loss in epoch(incomplete): 0.452685151178\n",
      "Epoch: 0 global_step 600 i 599 Avg loss in epoch(incomplete): 0.442854186743\n",
      "Epoch: 0 global_step 625 i 624 Avg loss in epoch(incomplete): 0.433539389873\n",
      "Epoch: 0 global_step 650 i 649 Avg loss in epoch(incomplete): 0.424701649753\n",
      "Epoch: 0 global_step 675 i 674 Avg loss in epoch(incomplete): 0.416290800351\n",
      "Epoch: 0 global_step 700 i 699 Avg loss in epoch(incomplete): 0.408355111288\n",
      "Epoch: 0 global_step 725 i 724 Avg loss in epoch(incomplete): 0.400869237924\n",
      "saving\n",
      "Epoch: 0 global_step 750 i 749 Avg loss in epoch(incomplete): 0.393772750417\n",
      "Epoch: 0 global_step 750 i 749 Avg loss in epoch(incomplete): 0.393772750417\n",
      "Epoch: 0 global_step 775 i 774 Avg loss in epoch(incomplete): 0.387037992497\n",
      "Epoch: 0 global_step 800 i 799 Avg loss in epoch(incomplete): 0.38064414423\n",
      "Epoch: 0 global_step 825 i 824 Avg loss in epoch(incomplete): 0.374603079178\n",
      "Epoch: 0 global_step 850 i 849 Avg loss in epoch(incomplete): 0.368851838918\n",
      "Epoch: 0 global_step 875 i 874 Avg loss in epoch(incomplete): 0.363382766758\n",
      "Epoch: 0 global_step 900 i 899 Avg loss in epoch(incomplete): 0.358184062425\n",
      "Epoch: 0 global_step 925 i 924 Avg loss in epoch(incomplete): 0.353246067134\n",
      "Epoch: 0 global_step 950 i 949 Avg loss in epoch(incomplete): 0.348550565415\n",
      "Epoch: 0 global_step 975 i 974 Avg loss in epoch(incomplete): 0.344058917623\n",
      "saving\n",
      "Epoch: 0 global_step 1000 i 999 Avg loss in epoch(incomplete): 0.339774815828\n",
      "Epoch: 0 global_step 1000 i 999 Avg loss in epoch(incomplete): 0.339774815828\n",
      "Epoch: 0 global_step 1025 i 1024 Avg loss in epoch(incomplete): 0.335678673619\n",
      "Epoch: 0 global_step 1050 i 1049 Avg loss in epoch(incomplete): 0.331765522886\n",
      "Epoch: 0 global_step 1075 i 1074 Avg loss in epoch(incomplete): 0.328017781848\n",
      "Epoch: 0 global_step 1100 i 1099 Avg loss in epoch(incomplete): 0.324437280988\n",
      "Epoch: 0 global_step 1125 i 1124 Avg loss in epoch(incomplete): 0.321005104913\n",
      "Epoch: 0 global_step 1150 i 1149 Avg loss in epoch(incomplete): 0.317717480089\n",
      "Epoch: 0 global_step 1175 i 1174 Avg loss in epoch(incomplete): 0.314556874354\n",
      "Epoch: 0 global_step 1200 i 1199 Avg loss in epoch(incomplete): 0.311530960128\n",
      "Epoch: 0 global_step 1225 i 1224 Avg loss in epoch(incomplete): 0.308607851036\n",
      "saving\n",
      "Epoch: 0 global_step 1250 i 1249 Avg loss in epoch(incomplete): 0.305799033391\n",
      "Epoch: 0 global_step 1250 i 1249 Avg loss in epoch(incomplete): 0.305799033391\n",
      "Epoch: 0 global_step 1275 i 1274 Avg loss in epoch(incomplete): 0.303101224934\n",
      "Epoch: 0 global_step 1300 i 1299 Avg loss in epoch(incomplete): 0.300500862186\n",
      "Epoch: 0 global_step 1325 i 1324 Avg loss in epoch(incomplete): 0.297998831283\n",
      "Epoch: 0 global_step 1350 i 1349 Avg loss in epoch(incomplete): 0.295584924839\n",
      "Epoch: 0 global_step 1375 i 1374 Avg loss in epoch(incomplete): 0.293244901549\n",
      "Epoch: 0 global_step 1400 i 1399 Avg loss in epoch(incomplete): 0.291004717669\n",
      "Epoch: 0 global_step 1425 i 1424 Avg loss in epoch(incomplete): 0.288827128274\n",
      "Epoch: 0 global_step 1450 i 1449 Avg loss in epoch(incomplete): 0.286719052658\n",
      "Epoch: 0 global_step 1475 i 1474 Avg loss in epoch(incomplete): 0.284678330219\n",
      "saving\n",
      "Epoch: 0 global_step 1500 i 1499 Avg loss in epoch(incomplete): 0.282709646841\n",
      "Epoch: 0 global_step 1500 i 1499 Avg loss in epoch(incomplete): 0.282709646841\n",
      "Epoch: 0 global_step 1525 i 1524 Avg loss in epoch(incomplete): 0.280804067586\n",
      "Epoch: 0 global_step 1550 i 1549 Avg loss in epoch(incomplete): 0.27894306004\n",
      "Epoch: 0 global_step 1575 i 1574 Avg loss in epoch(incomplete): 0.277155858676\n",
      "Epoch: 0 global_step 1600 i 1599 Avg loss in epoch(incomplete): 0.275430598054\n",
      "Epoch: 0 global_step 1625 i 1624 Avg loss in epoch(incomplete): 0.273744180047\n",
      "Epoch: 0 global_step 1650 i 1649 Avg loss in epoch(incomplete): 0.27211621625\n",
      "Epoch: 0 global_step 1675 i 1674 Avg loss in epoch(incomplete): 0.270535445863\n",
      "Epoch: 0 global_step 1700 i 1699 Avg loss in epoch(incomplete): 0.268998191848\n",
      "Epoch: 0 global_step 1725 i 1724 Avg loss in epoch(incomplete): 0.267507038626\n",
      "saving\n",
      "Epoch: 0 global_step 1750 i 1749 Avg loss in epoch(incomplete): 0.26606060596\n",
      "Epoch: 0 global_step 1750 i 1749 Avg loss in epoch(incomplete): 0.26606060596\n",
      "Epoch: 0 global_step 1775 i 1774 Avg loss in epoch(incomplete): 0.264645637257\n",
      "Epoch: 0 global_step 1800 i 1799 Avg loss in epoch(incomplete): 0.263277291548\n",
      "Epoch: 0 global_step 1825 i 1824 Avg loss in epoch(incomplete): 0.261937082606\n",
      "Epoch: 0 global_step 1850 i 1849 Avg loss in epoch(incomplete): 0.260648678606\n",
      "Epoch: 0 global_step 1875 i 1874 Avg loss in epoch(incomplete): 0.25938023603\n",
      "Epoch: 0 global_step 1900 i 1899 Avg loss in epoch(incomplete): 0.258162287654\n",
      "Epoch: 0 global_step 1925 i 1924 Avg loss in epoch(incomplete): 0.256973752766\n",
      "Epoch: 0 global_step 1950 i 1949 Avg loss in epoch(incomplete): 0.255794269206\n",
      "Epoch: 0 global_step 1975 i 1974 Avg loss in epoch(incomplete): 0.254653178906\n",
      "saving\n",
      "Epoch: 0 global_step 2000 i 1999 Avg loss in epoch(incomplete): 0.253546554141\n",
      "Epoch: 0 global_step 2000 i 1999 Avg loss in epoch(incomplete): 0.253546554141\n",
      "Epoch: 0 global_step 2025 i 2024 Avg loss in epoch(incomplete): 0.2524631609\n",
      "Epoch: 0 global_step 2050 i 2049 Avg loss in epoch(incomplete): 0.251399180184\n",
      "Epoch: 0 global_step 2075 i 2074 Avg loss in epoch(incomplete): 0.250363674315\n",
      "Epoch: 0 global_step 2100 i 2099 Avg loss in epoch(incomplete): 0.24935227795\n",
      "Epoch: 0 global_step 2125 i 2124 Avg loss in epoch(incomplete): 0.248365272816\n",
      "Epoch: 0 global_step 2150 i 2149 Avg loss in epoch(incomplete): 0.24738880346\n",
      "Epoch: 0 global_step 2175 i 2174 Avg loss in epoch(incomplete): 0.246446260947\n",
      "Epoch: 0 global_step 2200 i 2199 Avg loss in epoch(incomplete): 0.245520669317\n",
      "Epoch: 0 global_step 2225 i 2224 Avg loss in epoch(incomplete): 0.244615150683\n",
      "saving\n",
      "Epoch: 0 global_step 2250 i 2249 Avg loss in epoch(incomplete): 0.243735981352\n",
      "Epoch: 0 global_step 2250 i 2249 Avg loss in epoch(incomplete): 0.243735981352\n",
      "Epoch: 0 global_step 2275 i 2274 Avg loss in epoch(incomplete): 0.242880701619\n",
      "Epoch: 0 global_step 2300 i 2299 Avg loss in epoch(incomplete): 0.242043387119\n",
      "Epoch: 0 global_step 2325 i 2324 Avg loss in epoch(incomplete): 0.241214990622\n",
      "Epoch: 0 global_step 2350 i 2349 Avg loss in epoch(incomplete): 0.24041249045\n",
      "Epoch: 0 global_step 2375 i 2374 Avg loss in epoch(incomplete): 0.239631274085\n",
      "Epoch: 0 global_step 2400 i 2399 Avg loss in epoch(incomplete): 0.238850221007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 global_step 2425 i 2424 Avg loss in epoch(incomplete): 0.238103302066\n",
      "Epoch: 0 global_step 2450 i 2449 Avg loss in epoch(incomplete): 0.2373600893\n",
      "Epoch: 0 global_step 2475 i 2474 Avg loss in epoch(incomplete): 0.236629561686\n",
      "saving\n",
      "Epoch: 0 global_step 2500 i 2499 Avg loss in epoch(incomplete): 0.235927727032\n",
      "Epoch: 0 global_step 2500 i 2499 Avg loss in epoch(incomplete): 0.235927727032\n",
      "Epoch: 0 global_step 2525 i 2524 Avg loss in epoch(incomplete): 0.235235711732\n",
      "Epoch: 0 global_step 2550 i 2549 Avg loss in epoch(incomplete): 0.234557141218\n",
      "Epoch: 0 global_step 2575 i 2574 Avg loss in epoch(incomplete): 0.233887859322\n",
      "Epoch: 0 global_step 2600 i 2599 Avg loss in epoch(incomplete): 0.23322776219\n",
      "Epoch: 0 global_step 2625 i 2624 Avg loss in epoch(incomplete): 0.232581459301\n",
      "Epoch: 0 global_step 2650 i 2649 Avg loss in epoch(incomplete): 0.231946900909\n",
      "Epoch: 0 global_step 2675 i 2674 Avg loss in epoch(incomplete): 0.231328336986\n",
      "Epoch: 0 global_step 2700 i 2699 Avg loss in epoch(incomplete): 0.230732031674\n",
      "Epoch: 0 global_step 2725 i 2724 Avg loss in epoch(incomplete): 0.230131555539\n",
      "saving\n",
      "Epoch: 0 global_step 2750 i 2749 Avg loss in epoch(incomplete): 0.229537601482\n",
      "Epoch: 0 global_step 2750 i 2749 Avg loss in epoch(incomplete): 0.229537601482\n",
      "Epoch: 0 global_step 2775 i 2774 Avg loss in epoch(incomplete): 0.228962273211\n",
      "Epoch: 0 global_step 2800 i 2799 Avg loss in epoch(incomplete): 0.228388279426\n",
      "Epoch: 0 global_step 2825 i 2824 Avg loss in epoch(incomplete): 0.227826048225\n",
      "Epoch: 0 global_step 2850 i 2849 Avg loss in epoch(incomplete): 0.227271472022\n",
      "Epoch: 0 global_step 2875 i 2874 Avg loss in epoch(incomplete): 0.226729101248\n",
      "Epoch: 0 global_step 2900 i 2899 Avg loss in epoch(incomplete): 0.226201712063\n",
      "Epoch: 0 global_step 2925 i 2924 Avg loss in epoch(incomplete): 0.225680808527\n",
      "Epoch: 0 global_step 2950 i 2949 Avg loss in epoch(incomplete): 0.225165984686\n",
      "Epoch: 0 global_step 2975 i 2974 Avg loss in epoch(incomplete): 0.224675368156\n",
      "saving\n",
      "Epoch: 0 global_step 3000 i 2999 Avg loss in epoch(incomplete): 0.224184404929\n",
      "Epoch: 0 global_step 3000 i 2999 Avg loss in epoch(incomplete): 0.224184404929\n",
      "Epoch: 0 global_step 3025 i 3024 Avg loss in epoch(incomplete): 0.223691173403\n",
      "Epoch: 0 global_step 3050 i 3049 Avg loss in epoch(incomplete): 0.223212883663\n",
      "Epoch: 0 global_step 3075 i 3074 Avg loss in epoch(incomplete): 0.222746240812\n",
      "Epoch: 0 global_step 3100 i 3099 Avg loss in epoch(incomplete): 0.222285307896\n",
      "Epoch: 0 global_step 3125 i 3124 Avg loss in epoch(incomplete): 0.221834120722\n",
      "Epoch: 0 global_step 3150 i 3149 Avg loss in epoch(incomplete): 0.221386458481\n",
      "Epoch: 0 global_step 3175 i 3174 Avg loss in epoch(incomplete): 0.220942736587\n",
      "Epoch: 0 global_step 3200 i 3199 Avg loss in epoch(incomplete): 0.220502128741\n",
      "Epoch: 0 global_step 3225 i 3224 Avg loss in epoch(incomplete): 0.220074800003\n",
      "saving\n",
      "Epoch: 0 global_step 3250 i 3249 Avg loss in epoch(incomplete): 0.219652993074\n",
      "Epoch: 0 global_step 3250 i 3249 Avg loss in epoch(incomplete): 0.219652993074\n",
      "Epoch: 0 global_step 3275 i 3274 Avg loss in epoch(incomplete): 0.219244298252\n",
      "Epoch: 0 global_step 3300 i 3299 Avg loss in epoch(incomplete): 0.218834739756\n",
      "Epoch: 0 global_step 3325 i 3324 Avg loss in epoch(incomplete): 0.218425450486\n",
      "Epoch: 0 global_step 3350 i 3349 Avg loss in epoch(incomplete): 0.218026873732\n",
      "Epoch: 0 global_step 3375 i 3374 Avg loss in epoch(incomplete): 0.217635584244\n",
      "Epoch: 0 global_step 3400 i 3399 Avg loss in epoch(incomplete): 0.217243348404\n",
      "Epoch: 0 global_step 3425 i 3424 Avg loss in epoch(incomplete): 0.216861494292\n",
      "Epoch: 0 global_step 3450 i 3449 Avg loss in epoch(incomplete): 0.216477185108\n",
      "Epoch: 0 global_step 3475 i 3474 Avg loss in epoch(incomplete): 0.216107198566\n",
      "saving\n",
      "Epoch: 0 global_step 3500 i 3499 Avg loss in epoch(incomplete): 0.215746306368\n",
      "Epoch: 0 global_step 3500 i 3499 Avg loss in epoch(incomplete): 0.215746306368\n",
      "Epoch: 0 global_step 3525 i 3524 Avg loss in epoch(incomplete): 0.215391814755\n",
      "Epoch: 0 global_step 3550 i 3549 Avg loss in epoch(incomplete): 0.215036168296\n",
      "Epoch: 0 global_step 3575 i 3574 Avg loss in epoch(incomplete): 0.214681740528\n",
      "Epoch: 0 global_step 3600 i 3599 Avg loss in epoch(incomplete): 0.214334505503\n",
      "Epoch: 0 global_step 3625 i 3624 Avg loss in epoch(incomplete): 0.213999633214\n",
      "Epoch: 0 global_step 3650 i 3649 Avg loss in epoch(incomplete): 0.213663040677\n",
      "Epoch: 0 global_step 3675 i 3674 Avg loss in epoch(incomplete): 0.213332488152\n",
      "Epoch: 0 global_step 3700 i 3699 Avg loss in epoch(incomplete): 0.213002146386\n",
      "Epoch: 0 global_step 3725 i 3724 Avg loss in epoch(incomplete): 0.212681302536\n",
      "saving\n",
      "Epoch: 0 global_step 3750 i 3749 Avg loss in epoch(incomplete): 0.212366497719\n",
      "Epoch: 0 global_step 3750 i 3749 Avg loss in epoch(incomplete): 0.212366497719\n",
      "Epoch: 0 global_step 3775 i 3774 Avg loss in epoch(incomplete): 0.212057010129\n",
      "Epoch: 0 global_step 3800 i 3799 Avg loss in epoch(incomplete): 0.211739179755\n",
      "Epoch: 0 global_step 3825 i 3824 Avg loss in epoch(incomplete): 0.211434754266\n",
      "Epoch: 0 global_step 3850 i 3849 Avg loss in epoch(incomplete): 0.211130383673\n",
      "Epoch: 0 global_step 3875 i 3874 Avg loss in epoch(incomplete): 0.210835647806\n",
      "Epoch: 0 global_step 3900 i 3899 Avg loss in epoch(incomplete): 0.210541220949\n",
      "Epoch: 0 global_step 3925 i 3924 Avg loss in epoch(incomplete): 0.210245942397\n",
      "Epoch: 0 global_step 3950 i 3949 Avg loss in epoch(incomplete): 0.209962598478\n",
      "Epoch: 0 global_step 3975 i 3974 Avg loss in epoch(incomplete): 0.209677374254\n",
      "saving\n",
      "Epoch: 0 global_step 4000 i 3999 Avg loss in epoch(incomplete): 0.209391958617\n",
      "Epoch: 0 global_step 4000 i 3999 Avg loss in epoch(incomplete): 0.209391958617\n",
      "Epoch: 0 global_step 4025 i 4024 Avg loss in epoch(incomplete): 0.209110520315\n",
      "Epoch: 0 global_step 4050 i 4049 Avg loss in epoch(incomplete): 0.208839130497\n",
      "Epoch: 0 global_step 4075 i 4074 Avg loss in epoch(incomplete): 0.2085693201\n",
      "Epoch: 0 global_step 4100 i 4099 Avg loss in epoch(incomplete): 0.208300834614\n",
      "Epoch: 0 global_step 4125 i 4124 Avg loss in epoch(incomplete): 0.208034797007\n",
      "Epoch: 0 global_step 4150 i 4149 Avg loss in epoch(incomplete): 0.207782836018\n",
      "Epoch: 0 global_step 4175 i 4174 Avg loss in epoch(incomplete): 0.207521983953\n",
      "Epoch: 0 global_step 4200 i 4199 Avg loss in epoch(incomplete): 0.20726831781\n",
      "Epoch: 0 global_step 4225 i 4224 Avg loss in epoch(incomplete): 0.207014282649\n",
      "saving\n",
      "Epoch: 0 global_step 4250 i 4249 Avg loss in epoch(incomplete): 0.206766503225\n",
      "Epoch: 0 global_step 4250 i 4249 Avg loss in epoch(incomplete): 0.206766503225\n",
      "Epoch: 0 global_step 4275 i 4274 Avg loss in epoch(incomplete): 0.206521343774\n",
      "Epoch: 0 global_step 4300 i 4299 Avg loss in epoch(incomplete): 0.20628687519\n",
      "Epoch: 0 global_step 4325 i 4324 Avg loss in epoch(incomplete): 0.206044515451\n",
      "Epoch: 0 global_step 4350 i 4349 Avg loss in epoch(incomplete): 0.205802636801\n",
      "Epoch: 0 global_step 4375 i 4374 Avg loss in epoch(incomplete): 0.205564599892\n",
      "Epoch: 0 global_step 4400 i 4399 Avg loss in epoch(incomplete): 0.205327964256\n",
      "Epoch: 0 global_step 4425 i 4424 Avg loss in epoch(incomplete): 0.205104777719\n",
      "Epoch: 0 global_step 4450 i 4449 Avg loss in epoch(incomplete): 0.204881119557\n",
      "Epoch: 0 global_step 4475 i 4474 Avg loss in epoch(incomplete): 0.204654979799\n",
      "saving\n",
      "Epoch: 0 global_step 4500 i 4499 Avg loss in epoch(incomplete): 0.204442064007\n",
      "Epoch: 0 global_step 4500 i 4499 Avg loss in epoch(incomplete): 0.204442064007\n",
      "Epoch: 0 global_step 4525 i 4524 Avg loss in epoch(incomplete): 0.204227889516\n",
      "Epoch: 0 global_step 4550 i 4549 Avg loss in epoch(incomplete): 0.204010485502\n",
      "Epoch: 0 global_step 4575 i 4574 Avg loss in epoch(incomplete): 0.20379487164\n",
      "Epoch: 0 global_step 4600 i 4599 Avg loss in epoch(incomplete): 0.203581252769\n",
      "Epoch: 0 global_step 4625 i 4624 Avg loss in epoch(incomplete): 0.203375509153\n",
      "Epoch: 0 global_step 4650 i 4649 Avg loss in epoch(incomplete): 0.203166769185\n",
      "Epoch: 0 global_step 4675 i 4674 Avg loss in epoch(incomplete): 0.202961698369\n",
      "Epoch: 0 global_step 4700 i 4699 Avg loss in epoch(incomplete): 0.202759461447\n",
      "Epoch: 0 global_step 4725 i 4724 Avg loss in epoch(incomplete): 0.202562728499\n",
      "saving\n",
      "Epoch: 0 global_step 4750 i 4749 Avg loss in epoch(incomplete): 0.202370874157\n",
      "Epoch: 0 global_step 4750 i 4749 Avg loss in epoch(incomplete): 0.202370874157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 global_step 4775 i 4774 Avg loss in epoch(incomplete): 0.202175258167\n",
      "Epoch: 0 global_step 4800 i 4799 Avg loss in epoch(incomplete): 0.201980660312\n",
      "Epoch: 0 global_step 4825 i 4824 Avg loss in epoch(incomplete): 0.201788363182\n",
      "Epoch: 0 global_step 4850 i 4849 Avg loss in epoch(incomplete): 0.201602485023\n",
      "Epoch: 0 global_step 4875 i 4874 Avg loss in epoch(incomplete): 0.201419401563\n",
      "Epoch: 0 global_step 4900 i 4899 Avg loss in epoch(incomplete): 0.201235611186\n",
      "Epoch: 0 global_step 4925 i 4924 Avg loss in epoch(incomplete): 0.201051071465\n",
      "Epoch: 0 global_step 4950 i 4949 Avg loss in epoch(incomplete): 0.200864682691\n",
      "Epoch: 0 global_step 4975 i 4974 Avg loss in epoch(incomplete): 0.200684511712\n",
      "saving\n",
      "Epoch: 0 global_step 5000 i 4999 Avg loss in epoch(incomplete): 0.20050357081\n",
      "Epoch: 0 global_step 5000 i 4999 Avg loss in epoch(incomplete): 0.20050357081\n",
      "Epoch: 0 global_step 5025 i 5024 Avg loss in epoch(incomplete): 0.200329421174\n",
      "Epoch: 0 global_step 5050 i 5049 Avg loss in epoch(incomplete): 0.200154894101\n",
      "Epoch: 0 global_step 5075 i 5074 Avg loss in epoch(incomplete): 0.19998269683\n",
      "Epoch: 0 global_step 5100 i 5099 Avg loss in epoch(incomplete): 0.199804865534\n",
      "Epoch: 0 global_step 5125 i 5124 Avg loss in epoch(incomplete): 0.199639365757\n",
      "Epoch: 0 global_step 5150 i 5149 Avg loss in epoch(incomplete): 0.199470420561\n",
      "Epoch: 0 global_step 5175 i 5174 Avg loss in epoch(incomplete): 0.199309520615\n",
      "Epoch: 0 global_step 5200 i 5199 Avg loss in epoch(incomplete): 0.199141030016\n",
      "Epoch: 0 global_step 5225 i 5224 Avg loss in epoch(incomplete): 0.198975023054\n",
      "saving\n",
      "Epoch: 0 global_step 5250 i 5249 Avg loss in epoch(incomplete): 0.19881744127\n",
      "Epoch: 0 global_step 5250 i 5249 Avg loss in epoch(incomplete): 0.19881744127\n",
      "Epoch: 0 global_step 5275 i 5274 Avg loss in epoch(incomplete): 0.198657587535\n",
      "Epoch: 0 global_step 5300 i 5299 Avg loss in epoch(incomplete): 0.198500198072\n",
      "Epoch: 0 global_step 5325 i 5324 Avg loss in epoch(incomplete): 0.19833987095\n",
      "Epoch: 0 global_step 5350 i 5349 Avg loss in epoch(incomplete): 0.198188678528\n",
      "Epoch: 0 global_step 5375 i 5374 Avg loss in epoch(incomplete): 0.198032698981\n",
      "Epoch: 0 global_step 5400 i 5399 Avg loss in epoch(incomplete): 0.197887528917\n",
      "Epoch: 0 global_step 5425 i 5424 Avg loss in epoch(incomplete): 0.197733631557\n",
      "Epoch: 0 global_step 5450 i 5449 Avg loss in epoch(incomplete): 0.197584054861\n",
      "Epoch: 0 global_step 5475 i 5474 Avg loss in epoch(incomplete): 0.197434054518\n",
      "saving\n",
      "Epoch: 0 global_step 5500 i 5499 Avg loss in epoch(incomplete): 0.197285630654\n",
      "Epoch: 0 global_step 5500 i 5499 Avg loss in epoch(incomplete): 0.197285630654\n",
      "Epoch: 0 global_step 5525 i 5524 Avg loss in epoch(incomplete): 0.197138064603\n",
      "Epoch: 0 global_step 5550 i 5549 Avg loss in epoch(incomplete): 0.196988704664\n",
      "Epoch: 0 global_step 5575 i 5574 Avg loss in epoch(incomplete): 0.196843578511\n",
      "Epoch: 0 global_step 5600 i 5599 Avg loss in epoch(incomplete): 0.196692482175\n",
      "Epoch: 0 global_step 5625 i 5624 Avg loss in epoch(incomplete): 0.196548329661\n",
      "Epoch: 0 global_step 5650 i 5649 Avg loss in epoch(incomplete): 0.196407829473\n",
      "Epoch: 0 global_step 5675 i 5674 Avg loss in epoch(incomplete): 0.196268206664\n",
      "Epoch: 0 global_step 5700 i 5699 Avg loss in epoch(incomplete): 0.196131124442\n",
      "Epoch: 0 global_step 5725 i 5724 Avg loss in epoch(incomplete): 0.195994438667\n",
      "saving\n",
      "Epoch: 0 global_step 5750 i 5749 Avg loss in epoch(incomplete): 0.19585870656\n",
      "Epoch: 0 global_step 5750 i 5749 Avg loss in epoch(incomplete): 0.19585870656\n",
      "Epoch: 0 global_step 5775 i 5774 Avg loss in epoch(incomplete): 0.195726494903\n",
      "Epoch: 0 global_step 5800 i 5799 Avg loss in epoch(incomplete): 0.195590464994\n",
      "Epoch: 0 global_step 5825 i 5824 Avg loss in epoch(incomplete): 0.195458311326\n",
      "Epoch: 0 global_step 5850 i 5849 Avg loss in epoch(incomplete): 0.195324130025\n",
      "Epoch: 0 global_step 5875 i 5874 Avg loss in epoch(incomplete): 0.195195292696\n",
      "Epoch: 0 global_step 5900 i 5899 Avg loss in epoch(incomplete): 0.195061372372\n",
      "Epoch: 0 global_step 5925 i 5924 Avg loss in epoch(incomplete): 0.19493318472\n",
      "Epoch: 0 global_step 5950 i 5949 Avg loss in epoch(incomplete): 0.194806628157\n",
      "Epoch: 0 global_step 5975 i 5974 Avg loss in epoch(incomplete): 0.194682324214\n",
      "saving\n",
      "Epoch: 0 global_step 6000 i 5999 Avg loss in epoch(incomplete): 0.194555560278\n",
      "Epoch: 0 global_step 6000 i 5999 Avg loss in epoch(incomplete): 0.194555560278\n",
      "Epoch: 0 global_step 6025 i 6024 Avg loss in epoch(incomplete): 0.194427623435\n",
      "Epoch: 0 global_step 6050 i 6049 Avg loss in epoch(incomplete): 0.194305170511\n",
      "Epoch: 0 global_step 6075 i 6074 Avg loss in epoch(incomplete): 0.194184058287\n",
      "Epoch: 0 global_step 6100 i 6099 Avg loss in epoch(incomplete): 0.194070097763\n",
      "Epoch: 0 global_step 6125 i 6124 Avg loss in epoch(incomplete): 0.193948355641\n",
      "Epoch: 0 global_step 6150 i 6149 Avg loss in epoch(incomplete): 0.193829265288\n",
      "Epoch: 0 global_step 6175 i 6174 Avg loss in epoch(incomplete): 0.193710775822\n",
      "Epoch: 0 global_step 6200 i 6199 Avg loss in epoch(incomplete): 0.193593019069\n",
      "Epoch: 0 global_step 6225 i 6224 Avg loss in epoch(incomplete): 0.193477134058\n",
      "saving\n",
      "Epoch: 0 global_step 6250 i 6249 Avg loss in epoch(incomplete): 0.193362257781\n",
      "Epoch: 0 global_step 6250 i 6249 Avg loss in epoch(incomplete): 0.193362257781\n",
      "Epoch: 0 global_step 6275 i 6274 Avg loss in epoch(incomplete): 0.193247591281\n",
      "Epoch: 0 global_step 6300 i 6299 Avg loss in epoch(incomplete): 0.193138046161\n",
      "Epoch: 0 global_step 6325 i 6324 Avg loss in epoch(incomplete): 0.193030670566\n",
      "Epoch: 0 global_step 6350 i 6349 Avg loss in epoch(incomplete): 0.192921216274\n",
      "Epoch: 0 global_step 6375 i 6374 Avg loss in epoch(incomplete): 0.192813110943\n",
      "Epoch: 0 global_step 6400 i 6399 Avg loss in epoch(incomplete): 0.19270591625\n",
      "Epoch: 0 global_step 6425 i 6424 Avg loss in epoch(incomplete): 0.19259504975\n",
      "Epoch: 0 global_step 6450 i 6449 Avg loss in epoch(incomplete): 0.192486275247\n",
      "Epoch: 0 global_step 6475 i 6474 Avg loss in epoch(incomplete): 0.192379340815\n",
      "saving\n",
      "Epoch: 0 global_step 6500 i 6499 Avg loss in epoch(incomplete): 0.192273674701\n",
      "Epoch: 0 global_step 6500 i 6499 Avg loss in epoch(incomplete): 0.192273674701\n",
      "Epoch: 0 global_step 6525 i 6524 Avg loss in epoch(incomplete): 0.19216776767\n",
      "Epoch: 0 global_step 6550 i 6549 Avg loss in epoch(incomplete): 0.192065432347\n",
      "Epoch: 0 global_step 6575 i 6574 Avg loss in epoch(incomplete): 0.19196379298\n",
      "Epoch: 0 global_step 6600 i 6599 Avg loss in epoch(incomplete): 0.191859957567\n",
      "Epoch: 0 global_step 6625 i 6624 Avg loss in epoch(incomplete): 0.191759030358\n",
      "Epoch: 0 global_step 6650 i 6649 Avg loss in epoch(incomplete): 0.19166088225\n",
      "Epoch: 0 global_step 6675 i 6674 Avg loss in epoch(incomplete): 0.191562283568\n",
      "Epoch: 0 global_step 6700 i 6699 Avg loss in epoch(incomplete): 0.191460591815\n",
      "Epoch: 0 global_step 6725 i 6724 Avg loss in epoch(incomplete): 0.191365146978\n",
      "saving\n",
      "Epoch: 0 global_step 6750 i 6749 Avg loss in epoch(incomplete): 0.1912668599\n",
      "Epoch: 0 global_step 6750 i 6749 Avg loss in epoch(incomplete): 0.1912668599\n",
      "Epoch: 0 global_step 6775 i 6774 Avg loss in epoch(incomplete): 0.191171666487\n",
      "Epoch: 0 global_step 6800 i 6799 Avg loss in epoch(incomplete): 0.19107946975\n",
      "Epoch: 0 global_step 6825 i 6824 Avg loss in epoch(incomplete): 0.190983805425\n",
      "Epoch: 0 global_step 6850 i 6849 Avg loss in epoch(incomplete): 0.190888155662\n",
      "Epoch: 0 global_step 6875 i 6874 Avg loss in epoch(incomplete): 0.190789153106\n",
      "Epoch: 0 global_step 6900 i 6899 Avg loss in epoch(incomplete): 0.190694611241\n",
      "Epoch: 0 global_step 6925 i 6924 Avg loss in epoch(incomplete): 0.190604464257\n",
      "Epoch: 0 global_step 6950 i 6949 Avg loss in epoch(incomplete): 0.190511581456\n",
      "Epoch: 0 global_step 6975 i 6974 Avg loss in epoch(incomplete): 0.190421558747\n",
      "saving\n",
      "Epoch: 0 global_step 7000 i 6999 Avg loss in epoch(incomplete): 0.190329029326\n",
      "Epoch: 0 global_step 7000 i 6999 Avg loss in epoch(incomplete): 0.190329029326\n",
      "Epoch: 0 global_step 7025 i 7024 Avg loss in epoch(incomplete): 0.190238438751\n",
      "Epoch: 0 global_step 7050 i 7049 Avg loss in epoch(incomplete): 0.190142192371\n",
      "Epoch: 0 global_step 7075 i 7074 Avg loss in epoch(incomplete): 0.190054796928\n",
      "Epoch: 0 global_step 7100 i 7099 Avg loss in epoch(incomplete): 0.189966632554\n",
      "Epoch: 0 global_step 7125 i 7124 Avg loss in epoch(incomplete): 0.189881621909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 global_step 7150 i 7149 Avg loss in epoch(incomplete): 0.18979552894\n",
      "Epoch: 0 global_step 7175 i 7174 Avg loss in epoch(incomplete): 0.189707957762\n",
      "Epoch: 0 global_step 7200 i 7199 Avg loss in epoch(incomplete): 0.189617131744\n",
      "Epoch: 0 global_step 7225 i 7224 Avg loss in epoch(incomplete): 0.189534883375\n",
      "saving\n",
      "Epoch: 0 global_step 7250 i 7249 Avg loss in epoch(incomplete): 0.189449596424\n",
      "Epoch: 0 global_step 7250 i 7249 Avg loss in epoch(incomplete): 0.189449596424\n",
      "Epoch: 0 global_step 7275 i 7274 Avg loss in epoch(incomplete): 0.189367604215\n",
      "Epoch: 0 global_step 7300 i 7299 Avg loss in epoch(incomplete): 0.189285849482\n",
      "Epoch: 0 global_step 7325 i 7324 Avg loss in epoch(incomplete): 0.189203282243\n",
      "Epoch: 0 global_step 7350 i 7349 Avg loss in epoch(incomplete): 0.189119581825\n",
      "Epoch: 0 global_step 7375 i 7374 Avg loss in epoch(incomplete): 0.189038853421\n",
      "Epoch: 0 global_step 7400 i 7399 Avg loss in epoch(incomplete): 0.188956545307\n",
      "Epoch: 0 global_step 7425 i 7424 Avg loss in epoch(incomplete): 0.188875930851\n",
      "Epoch: 0 global_step 7450 i 7449 Avg loss in epoch(incomplete): 0.188797901617\n",
      "Epoch: 0 global_step 7475 i 7474 Avg loss in epoch(incomplete): 0.188719688999\n",
      "saving\n",
      "Epoch: 0 global_step 7500 i 7499 Avg loss in epoch(incomplete): 0.188638516871\n",
      "Epoch: 0 global_step 7500 i 7499 Avg loss in epoch(incomplete): 0.188638516871\n",
      "Epoch: 0 global_step 7525 i 7524 Avg loss in epoch(incomplete): 0.188562618767\n",
      "Epoch: 0 global_step 7550 i 7549 Avg loss in epoch(incomplete): 0.18848592605\n",
      "Epoch: 0 global_step 7575 i 7574 Avg loss in epoch(incomplete): 0.188407325273\n",
      "Epoch: 0 global_step 7600 i 7599 Avg loss in epoch(incomplete): 0.188331922355\n",
      "Epoch: 0 global_step 7625 i 7624 Avg loss in epoch(incomplete): 0.188253754524\n",
      "Epoch: 0 global_step 7650 i 7649 Avg loss in epoch(incomplete): 0.188177280276\n",
      "Epoch: 0 global_step 7675 i 7674 Avg loss in epoch(incomplete): 0.18810250246\n",
      "Epoch: 0 global_step 7700 i 7699 Avg loss in epoch(incomplete): 0.18802598711\n",
      "Epoch: 0 global_step 7725 i 7724 Avg loss in epoch(incomplete): 0.187947707533\n",
      "saving\n",
      "Epoch: 0 global_step 7750 i 7749 Avg loss in epoch(incomplete): 0.18787235937\n",
      "Epoch: 0 global_step 7750 i 7749 Avg loss in epoch(incomplete): 0.18787235937\n",
      "Epoch: 0 global_step 7775 i 7774 Avg loss in epoch(incomplete): 0.187799846256\n",
      "Epoch: 0 global_step 7800 i 7799 Avg loss in epoch(incomplete): 0.187723913403\n",
      "Epoch: 0 global_step 7825 i 7824 Avg loss in epoch(incomplete): 0.187649998773\n",
      "Epoch: 0 global_step 7850 i 7849 Avg loss in epoch(incomplete): 0.187576211315\n",
      "Epoch: 0 global_step 7875 i 7874 Avg loss in epoch(incomplete): 0.187504845214\n",
      "Epoch: 0 global_step 7900 i 7899 Avg loss in epoch(incomplete): 0.187432563892\n",
      "Epoch: 0 global_step 7925 i 7924 Avg loss in epoch(incomplete): 0.187361949289\n",
      "Epoch: 0 global_step 7950 i 7949 Avg loss in epoch(incomplete): 0.187291908913\n",
      "Epoch: 0 global_step 7975 i 7974 Avg loss in epoch(incomplete): 0.187221896325\n",
      "saving\n",
      "Epoch: 0 global_step 8000 i 7999 Avg loss in epoch(incomplete): 0.187153077742\n",
      "Epoch: 0 global_step 8000 i 7999 Avg loss in epoch(incomplete): 0.187153077742\n",
      "Epoch: 0 global_step 8025 i 8024 Avg loss in epoch(incomplete): 0.187081930006\n",
      "Epoch: 0 global_step 8050 i 8049 Avg loss in epoch(incomplete): 0.187009979353\n",
      "Epoch: 0 global_step 8075 i 8074 Avg loss in epoch(incomplete): 0.1869423963\n",
      "Epoch: 0 global_step 8100 i 8099 Avg loss in epoch(incomplete): 0.186871762774\n",
      "Epoch: 0 global_step 8125 i 8124 Avg loss in epoch(incomplete): 0.186802711292\n",
      "Epoch: 0 global_step 8150 i 8149 Avg loss in epoch(incomplete): 0.186737144725\n",
      "Epoch: 0 global_step 8175 i 8174 Avg loss in epoch(incomplete): 0.186669563828\n",
      "Epoch: 0 global_step 8200 i 8199 Avg loss in epoch(incomplete): 0.186603130673\n",
      "Epoch: 0 global_step 8225 i 8224 Avg loss in epoch(incomplete): 0.186537211959\n",
      "saving\n",
      "Epoch: 0 global_step 8250 i 8249 Avg loss in epoch(incomplete): 0.186475049633\n",
      "Epoch: 0 global_step 8250 i 8249 Avg loss in epoch(incomplete): 0.186475049633\n",
      "Epoch: 0 global_step 8275 i 8274 Avg loss in epoch(incomplete): 0.186408307808\n",
      "Epoch: 0 global_step 8300 i 8299 Avg loss in epoch(incomplete): 0.186346464177\n",
      "Epoch: 0 global_step 8325 i 8324 Avg loss in epoch(incomplete): 0.186280113969\n",
      "Epoch: 0 global_step 8350 i 8349 Avg loss in epoch(incomplete): 0.186219958922\n",
      "Epoch: 0 global_step 8375 i 8374 Avg loss in epoch(incomplete): 0.186155980295\n",
      "Epoch: 0 global_step 8400 i 8399 Avg loss in epoch(incomplete): 0.186095044026\n",
      "Epoch: 0 global_step 8425 i 8424 Avg loss in epoch(incomplete): 0.186035277297\n",
      "Epoch: 0 global_step 8450 i 8449 Avg loss in epoch(incomplete): 0.185972407543\n",
      "Epoch: 0 global_step 8475 i 8474 Avg loss in epoch(incomplete): 0.185912430831\n",
      "saving\n",
      "Epoch: 0 global_step 8500 i 8499 Avg loss in epoch(incomplete): 0.185848848909\n",
      "Epoch: 0 global_step 8500 i 8499 Avg loss in epoch(incomplete): 0.185848848909\n",
      "Epoch: 0 global_step 8525 i 8524 Avg loss in epoch(incomplete): 0.185788836977\n",
      "Epoch: 0 global_step 8550 i 8549 Avg loss in epoch(incomplete): 0.185726972224\n",
      "Epoch: 0 global_step 8575 i 8574 Avg loss in epoch(incomplete): 0.185665389979\n",
      "Epoch: 0 global_step 8600 i 8599 Avg loss in epoch(incomplete): 0.185601696135\n",
      "Epoch: 0 global_step 8625 i 8624 Avg loss in epoch(incomplete): 0.185541095528\n",
      "Epoch: 0 global_step 8650 i 8649 Avg loss in epoch(incomplete): 0.18548583932\n",
      "Epoch: 0 global_step 8675 i 8674 Avg loss in epoch(incomplete): 0.185425745518\n",
      "saving\n",
      "Epoch: 0 global_step 8695 i 8694 Avg loss in epoch(incomplete): 0.18538024402\n",
      "Epoch: 1 global_step 8700 i 4 Avg loss in epoch(incomplete): 0.16329921484\n",
      "Epoch: 1 global_step 8725 i 29 Avg loss in epoch(incomplete): 0.165581293404\n",
      "saving\n",
      "Epoch: 1 global_step 8750 i 54 Avg loss in epoch(incomplete): 0.165315656228\n",
      "Epoch: 1 global_step 8750 i 54 Avg loss in epoch(incomplete): 0.165315656228\n",
      "Epoch: 1 global_step 8775 i 79 Avg loss in epoch(incomplete): 0.165027123876\n",
      "Epoch: 1 global_step 8800 i 104 Avg loss in epoch(incomplete): 0.165413706501\n",
      "Epoch: 1 global_step 8825 i 129 Avg loss in epoch(incomplete): 0.165193965687\n",
      "Epoch: 1 global_step 8850 i 154 Avg loss in epoch(incomplete): 0.165160610118\n",
      "Epoch: 1 global_step 8875 i 179 Avg loss in epoch(incomplete): 0.165193664283\n",
      "Epoch: 1 global_step 8900 i 204 Avg loss in epoch(incomplete): 0.165162579315\n",
      "Epoch: 1 global_step 8925 i 229 Avg loss in epoch(incomplete): 0.165237446712\n",
      "Epoch: 1 global_step 8950 i 254 Avg loss in epoch(incomplete): 0.165080053432\n",
      "Epoch: 1 global_step 8975 i 279 Avg loss in epoch(incomplete): 0.165019081799\n",
      "saving\n",
      "Epoch: 1 global_step 9000 i 304 Avg loss in epoch(incomplete): 0.165058989652\n",
      "Epoch: 1 global_step 9000 i 304 Avg loss in epoch(incomplete): 0.165058989652\n",
      "Epoch: 1 global_step 9025 i 329 Avg loss in epoch(incomplete): 0.165086036379\n",
      "Epoch: 1 global_step 9050 i 354 Avg loss in epoch(incomplete): 0.165101158073\n",
      "Epoch: 1 global_step 9075 i 379 Avg loss in epoch(incomplete): 0.165038957251\n",
      "Epoch: 1 global_step 9100 i 404 Avg loss in epoch(incomplete): 0.164956570665\n",
      "Epoch: 1 global_step 9125 i 429 Avg loss in epoch(incomplete): 0.164986374212\n",
      "Epoch: 1 global_step 9150 i 454 Avg loss in epoch(incomplete): 0.164975054447\n",
      "Epoch: 1 global_step 9175 i 479 Avg loss in epoch(incomplete): 0.164936646043\n",
      "Epoch: 1 global_step 9200 i 504 Avg loss in epoch(incomplete): 0.164960882274\n",
      "Epoch: 1 global_step 9225 i 529 Avg loss in epoch(incomplete): 0.164973433316\n",
      "saving\n",
      "Epoch: 1 global_step 9250 i 554 Avg loss in epoch(incomplete): 0.164950742566\n",
      "Epoch: 1 global_step 9250 i 554 Avg loss in epoch(incomplete): 0.164950742566\n",
      "Epoch: 1 global_step 9275 i 579 Avg loss in epoch(incomplete): 0.164961894525\n",
      "Epoch: 1 global_step 9300 i 604 Avg loss in epoch(incomplete): 0.164908792682\n",
      "Epoch: 1 global_step 9325 i 629 Avg loss in epoch(incomplete): 0.164906238611\n",
      "Epoch: 1 global_step 9350 i 654 Avg loss in epoch(incomplete): 0.16487314717\n",
      "Epoch: 1 global_step 9375 i 679 Avg loss in epoch(incomplete): 0.164866559996\n",
      "Epoch: 1 global_step 9400 i 704 Avg loss in epoch(incomplete): 0.164859109969\n",
      "Epoch: 1 global_step 9425 i 729 Avg loss in epoch(incomplete): 0.164860942184\n",
      "Epoch: 1 global_step 9450 i 754 Avg loss in epoch(incomplete): 0.164861565749\n",
      "Epoch: 1 global_step 9475 i 779 Avg loss in epoch(incomplete): 0.164871650877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n",
      "Epoch: 1 global_step 9500 i 804 Avg loss in epoch(incomplete): 0.164872848784\n",
      "Epoch: 1 global_step 9500 i 804 Avg loss in epoch(incomplete): 0.164872848784\n",
      "Epoch: 1 global_step 9525 i 829 Avg loss in epoch(incomplete): 0.16487275432\n",
      "Epoch: 1 global_step 9550 i 854 Avg loss in epoch(incomplete): 0.164829731232\n",
      "Epoch: 1 global_step 9575 i 879 Avg loss in epoch(incomplete): 0.164835617539\n",
      "Epoch: 1 global_step 9600 i 904 Avg loss in epoch(incomplete): 0.164843052477\n",
      "Epoch: 1 global_step 9625 i 929 Avg loss in epoch(incomplete): 0.164866798379\n",
      "Epoch: 1 global_step 9650 i 954 Avg loss in epoch(incomplete): 0.164888914858\n",
      "Epoch: 1 global_step 9675 i 979 Avg loss in epoch(incomplete): 0.164903297412\n",
      "Epoch: 1 global_step 9700 i 1004 Avg loss in epoch(incomplete): 0.16491463985\n",
      "Epoch: 1 global_step 9725 i 1029 Avg loss in epoch(incomplete): 0.164902459143\n",
      "saving\n",
      "Epoch: 1 global_step 9750 i 1054 Avg loss in epoch(incomplete): 0.164901748596\n",
      "Epoch: 1 global_step 9750 i 1054 Avg loss in epoch(incomplete): 0.164901748596\n",
      "Epoch: 1 global_step 9775 i 1079 Avg loss in epoch(incomplete): 0.164900329212\n",
      "Epoch: 1 global_step 9800 i 1104 Avg loss in epoch(incomplete): 0.164871006247\n",
      "Epoch: 1 global_step 9825 i 1129 Avg loss in epoch(incomplete): 0.164878641108\n",
      "Epoch: 1 global_step 9850 i 1154 Avg loss in epoch(incomplete): 0.164902044762\n",
      "Epoch: 1 global_step 9875 i 1179 Avg loss in epoch(incomplete): 0.164915284439\n",
      "Epoch: 1 global_step 9900 i 1204 Avg loss in epoch(incomplete): 0.164900401383\n",
      "Epoch: 1 global_step 9925 i 1229 Avg loss in epoch(incomplete): 0.164892113221\n",
      "Epoch: 1 global_step 9950 i 1254 Avg loss in epoch(incomplete): 0.164873739103\n",
      "Epoch: 1 global_step 9975 i 1279 Avg loss in epoch(incomplete): 0.164895905496\n",
      "saving\n",
      "Epoch: 1 global_step 10000 i 1304 Avg loss in epoch(incomplete): 0.164889126696\n",
      "Epoch: 1 global_step 10000 i 1304 Avg loss in epoch(incomplete): 0.164889126696\n",
      "Epoch: 1 global_step 10025 i 1329 Avg loss in epoch(incomplete): 0.164901605618\n",
      "Epoch: 1 global_step 10050 i 1354 Avg loss in epoch(incomplete): 0.164896056353\n",
      "Epoch: 1 global_step 10075 i 1379 Avg loss in epoch(incomplete): 0.164911629799\n",
      "Epoch: 1 global_step 10100 i 1404 Avg loss in epoch(incomplete): 0.16490606497\n",
      "Epoch: 1 global_step 10125 i 1429 Avg loss in epoch(incomplete): 0.164905811565\n",
      "Epoch: 1 global_step 10150 i 1454 Avg loss in epoch(incomplete): 0.164920566787\n",
      "Epoch: 1 global_step 10175 i 1479 Avg loss in epoch(incomplete): 0.164914588489\n",
      "Epoch: 1 global_step 10200 i 1504 Avg loss in epoch(incomplete): 0.164921966066\n",
      "Epoch: 1 global_step 10225 i 1529 Avg loss in epoch(incomplete): 0.164921942285\n",
      "saving\n",
      "Epoch: 1 global_step 10250 i 1554 Avg loss in epoch(incomplete): 0.164922693525\n",
      "Epoch: 1 global_step 10250 i 1554 Avg loss in epoch(incomplete): 0.164922693525\n",
      "Epoch: 1 global_step 10275 i 1579 Avg loss in epoch(incomplete): 0.164927268811\n",
      "Epoch: 1 global_step 10300 i 1604 Avg loss in epoch(incomplete): 0.164910775859\n",
      "Epoch: 1 global_step 10325 i 1629 Avg loss in epoch(incomplete): 0.164921926017\n",
      "Epoch: 1 global_step 10350 i 1654 Avg loss in epoch(incomplete): 0.164927595827\n",
      "Epoch: 1 global_step 10375 i 1679 Avg loss in epoch(incomplete): 0.164934400159\n",
      "Epoch: 1 global_step 10400 i 1704 Avg loss in epoch(incomplete): 0.164929811652\n",
      "Epoch: 1 global_step 10425 i 1729 Avg loss in epoch(incomplete): 0.164925844451\n",
      "Epoch: 1 global_step 10450 i 1754 Avg loss in epoch(incomplete): 0.164927891678\n",
      "Epoch: 1 global_step 10475 i 1779 Avg loss in epoch(incomplete): 0.164922903286\n",
      "saving\n",
      "Epoch: 1 global_step 10500 i 1804 Avg loss in epoch(incomplete): 0.164913245293\n",
      "Epoch: 1 global_step 10500 i 1804 Avg loss in epoch(incomplete): 0.164913245293\n",
      "Epoch: 1 global_step 10525 i 1829 Avg loss in epoch(incomplete): 0.164914510932\n",
      "Epoch: 1 global_step 10550 i 1854 Avg loss in epoch(incomplete): 0.164907536915\n",
      "Epoch: 1 global_step 10575 i 1879 Avg loss in epoch(incomplete): 0.164911956372\n",
      "Epoch: 1 global_step 10600 i 1904 Avg loss in epoch(incomplete): 0.164909402631\n",
      "Epoch: 1 global_step 10625 i 1929 Avg loss in epoch(incomplete): 0.164912273955\n",
      "Epoch: 1 global_step 10650 i 1954 Avg loss in epoch(incomplete): 0.164912720661\n",
      "Epoch: 1 global_step 10675 i 1979 Avg loss in epoch(incomplete): 0.164915935086\n",
      "Epoch: 1 global_step 10700 i 2004 Avg loss in epoch(incomplete): 0.164921899619\n",
      "Epoch: 1 global_step 10725 i 2029 Avg loss in epoch(incomplete): 0.164926551048\n",
      "saving\n",
      "Epoch: 1 global_step 10750 i 2054 Avg loss in epoch(incomplete): 0.1649297168\n",
      "Epoch: 1 global_step 10750 i 2054 Avg loss in epoch(incomplete): 0.1649297168\n",
      "Epoch: 1 global_step 10775 i 2079 Avg loss in epoch(incomplete): 0.164937877254\n",
      "Epoch: 1 global_step 10800 i 2104 Avg loss in epoch(incomplete): 0.164935667618\n",
      "Epoch: 1 global_step 10825 i 2129 Avg loss in epoch(incomplete): 0.164928471895\n",
      "Epoch: 1 global_step 10850 i 2154 Avg loss in epoch(incomplete): 0.164933991363\n",
      "Epoch: 1 global_step 10875 i 2179 Avg loss in epoch(incomplete): 0.164941445998\n",
      "Epoch: 1 global_step 10900 i 2204 Avg loss in epoch(incomplete): 0.164941416353\n",
      "Epoch: 1 global_step 10925 i 2229 Avg loss in epoch(incomplete): 0.164946381641\n",
      "Epoch: 1 global_step 10950 i 2254 Avg loss in epoch(incomplete): 0.164934702439\n",
      "Epoch: 1 global_step 10975 i 2279 Avg loss in epoch(incomplete): 0.164931022043\n",
      "saving\n",
      "Epoch: 1 global_step 11000 i 2304 Avg loss in epoch(incomplete): 0.164944209866\n",
      "Epoch: 1 global_step 11000 i 2304 Avg loss in epoch(incomplete): 0.164944209866\n",
      "Epoch: 1 global_step 11025 i 2329 Avg loss in epoch(incomplete): 0.164946975102\n",
      "Epoch: 1 global_step 11050 i 2354 Avg loss in epoch(incomplete): 0.1649502829\n",
      "Epoch: 1 global_step 11075 i 2379 Avg loss in epoch(incomplete): 0.164937167828\n",
      "Epoch: 1 global_step 11100 i 2404 Avg loss in epoch(incomplete): 0.164932184185\n",
      "Epoch: 1 global_step 11125 i 2429 Avg loss in epoch(incomplete): 0.164928047788\n",
      "Epoch: 1 global_step 11150 i 2454 Avg loss in epoch(incomplete): 0.164931418272\n",
      "Epoch: 1 global_step 11175 i 2479 Avg loss in epoch(incomplete): 0.164932193457\n",
      "Epoch: 1 global_step 11200 i 2504 Avg loss in epoch(incomplete): 0.164927306289\n",
      "Epoch: 1 global_step 11225 i 2529 Avg loss in epoch(incomplete): 0.164930255852\n",
      "saving\n",
      "Epoch: 1 global_step 11250 i 2554 Avg loss in epoch(incomplete): 0.164929611057\n",
      "Epoch: 1 global_step 11250 i 2554 Avg loss in epoch(incomplete): 0.164929611057\n",
      "Epoch: 1 global_step 11275 i 2579 Avg loss in epoch(incomplete): 0.164932644038\n",
      "Epoch: 1 global_step 11300 i 2604 Avg loss in epoch(incomplete): 0.164932505131\n",
      "Epoch: 1 global_step 11325 i 2629 Avg loss in epoch(incomplete): 0.16491612788\n",
      "Epoch: 1 global_step 11350 i 2654 Avg loss in epoch(incomplete): 0.164926746768\n",
      "Epoch: 1 global_step 11375 i 2679 Avg loss in epoch(incomplete): 0.164936760724\n",
      "Epoch: 1 global_step 11400 i 2704 Avg loss in epoch(incomplete): 0.164948621029\n",
      "Epoch: 1 global_step 11425 i 2729 Avg loss in epoch(incomplete): 0.164955943888\n",
      "Epoch: 1 global_step 11450 i 2754 Avg loss in epoch(incomplete): 0.16495477905\n",
      "Epoch: 1 global_step 11475 i 2779 Avg loss in epoch(incomplete): 0.1649441236\n",
      "saving\n",
      "Epoch: 1 global_step 11500 i 2804 Avg loss in epoch(incomplete): 0.16494024337\n",
      "Epoch: 1 global_step 11500 i 2804 Avg loss in epoch(incomplete): 0.16494024337\n",
      "Epoch: 1 global_step 11525 i 2829 Avg loss in epoch(incomplete): 0.164944442396\n",
      "Epoch: 1 global_step 11550 i 2854 Avg loss in epoch(incomplete): 0.164949857364\n",
      "Epoch: 1 global_step 11575 i 2879 Avg loss in epoch(incomplete): 0.164947140413\n",
      "Epoch: 1 global_step 11600 i 2904 Avg loss in epoch(incomplete): 0.164949021882\n",
      "Epoch: 1 global_step 11625 i 2929 Avg loss in epoch(incomplete): 0.164945707788\n",
      "Epoch: 1 global_step 11650 i 2954 Avg loss in epoch(incomplete): 0.164944993043\n",
      "Epoch: 1 global_step 11675 i 2979 Avg loss in epoch(incomplete): 0.164944382087\n",
      "Epoch: 1 global_step 11700 i 3004 Avg loss in epoch(incomplete): 0.164949673875\n",
      "Epoch: 1 global_step 11725 i 3029 Avg loss in epoch(incomplete): 0.16495104826\n",
      "saving\n",
      "Epoch: 1 global_step 11750 i 3054 Avg loss in epoch(incomplete): 0.164952922155\n",
      "Epoch: 1 global_step 11750 i 3054 Avg loss in epoch(incomplete): 0.164952922155\n",
      "Epoch: 1 global_step 11775 i 3079 Avg loss in epoch(incomplete): 0.164950338122\n",
      "Epoch: 1 global_step 11800 i 3104 Avg loss in epoch(incomplete): 0.164954207682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 global_step 11825 i 3129 Avg loss in epoch(incomplete): 0.164952303636\n",
      "Epoch: 1 global_step 11850 i 3154 Avg loss in epoch(incomplete): 0.164951063038\n",
      "Epoch: 1 global_step 11875 i 3179 Avg loss in epoch(incomplete): 0.164948415822\n",
      "Epoch: 1 global_step 11900 i 3204 Avg loss in epoch(incomplete): 0.164951080967\n",
      "Epoch: 1 global_step 11925 i 3229 Avg loss in epoch(incomplete): 0.16494443847\n",
      "Epoch: 1 global_step 11950 i 3254 Avg loss in epoch(incomplete): 0.164935975479\n",
      "Epoch: 1 global_step 11975 i 3279 Avg loss in epoch(incomplete): 0.164931085606\n",
      "saving\n",
      "Epoch: 1 global_step 12000 i 3304 Avg loss in epoch(incomplete): 0.16492766164\n",
      "Epoch: 1 global_step 12000 i 3304 Avg loss in epoch(incomplete): 0.16492766164\n",
      "Epoch: 1 global_step 12025 i 3329 Avg loss in epoch(incomplete): 0.164937074908\n",
      "Epoch: 1 global_step 12050 i 3354 Avg loss in epoch(incomplete): 0.16494261077\n",
      "Epoch: 1 global_step 12075 i 3379 Avg loss in epoch(incomplete): 0.164948703203\n",
      "Epoch: 1 global_step 12100 i 3404 Avg loss in epoch(incomplete): 0.164952272811\n",
      "Epoch: 1 global_step 12125 i 3429 Avg loss in epoch(incomplete): 0.164950820791\n",
      "Epoch: 1 global_step 12150 i 3454 Avg loss in epoch(incomplete): 0.164950844943\n",
      "Epoch: 1 global_step 12175 i 3479 Avg loss in epoch(incomplete): 0.164935692348\n",
      "Epoch: 1 global_step 12200 i 3504 Avg loss in epoch(incomplete): 0.164932139696\n",
      "Epoch: 1 global_step 12225 i 3529 Avg loss in epoch(incomplete): 0.164932221292\n",
      "saving\n",
      "Epoch: 1 global_step 12250 i 3554 Avg loss in epoch(incomplete): 0.164941785247\n",
      "Epoch: 1 global_step 12250 i 3554 Avg loss in epoch(incomplete): 0.164941785247\n",
      "Epoch: 1 global_step 12275 i 3579 Avg loss in epoch(incomplete): 0.164942149156\n",
      "Epoch: 1 global_step 12300 i 3604 Avg loss in epoch(incomplete): 0.164940774019\n",
      "Epoch: 1 global_step 12325 i 3629 Avg loss in epoch(incomplete): 0.16494595273\n",
      "Epoch: 1 global_step 12350 i 3654 Avg loss in epoch(incomplete): 0.164937217177\n",
      "Epoch: 1 global_step 12375 i 3679 Avg loss in epoch(incomplete): 0.164937203094\n",
      "Epoch: 1 global_step 12400 i 3704 Avg loss in epoch(incomplete): 0.164934654713\n",
      "Epoch: 1 global_step 12425 i 3729 Avg loss in epoch(incomplete): 0.164934741476\n",
      "Epoch: 1 global_step 12450 i 3754 Avg loss in epoch(incomplete): 0.164932253322\n",
      "Epoch: 1 global_step 12475 i 3779 Avg loss in epoch(incomplete): 0.164937213201\n",
      "saving\n",
      "Epoch: 1 global_step 12500 i 3804 Avg loss in epoch(incomplete): 0.164939035234\n",
      "Epoch: 1 global_step 12500 i 3804 Avg loss in epoch(incomplete): 0.164939035234\n",
      "Epoch: 1 global_step 12525 i 3829 Avg loss in epoch(incomplete): 0.164944286026\n",
      "Epoch: 1 global_step 12550 i 3854 Avg loss in epoch(incomplete): 0.164936108661\n",
      "Epoch: 1 global_step 12575 i 3879 Avg loss in epoch(incomplete): 0.164939128085\n",
      "Epoch: 1 global_step 12600 i 3904 Avg loss in epoch(incomplete): 0.164934143401\n",
      "Epoch: 1 global_step 12625 i 3929 Avg loss in epoch(incomplete): 0.164931532942\n",
      "Epoch: 1 global_step 12650 i 3954 Avg loss in epoch(incomplete): 0.164929248357\n",
      "Epoch: 1 global_step 12675 i 3979 Avg loss in epoch(incomplete): 0.164931592061\n",
      "Epoch: 1 global_step 12700 i 4004 Avg loss in epoch(incomplete): 0.164925138174\n",
      "Epoch: 1 global_step 12725 i 4029 Avg loss in epoch(incomplete): 0.164925837121\n",
      "saving\n",
      "Epoch: 1 global_step 12750 i 4054 Avg loss in epoch(incomplete): 0.164925719432\n",
      "Epoch: 1 global_step 12750 i 4054 Avg loss in epoch(incomplete): 0.164925719432\n",
      "Epoch: 1 global_step 12775 i 4079 Avg loss in epoch(incomplete): 0.164926739512\n",
      "Epoch: 1 global_step 12800 i 4104 Avg loss in epoch(incomplete): 0.164926935255\n",
      "Epoch: 1 global_step 12825 i 4129 Avg loss in epoch(incomplete): 0.164925895245\n",
      "Epoch: 1 global_step 12850 i 4154 Avg loss in epoch(incomplete): 0.16493022207\n",
      "Epoch: 1 global_step 12875 i 4179 Avg loss in epoch(incomplete): 0.164927205518\n",
      "Epoch: 1 global_step 12900 i 4204 Avg loss in epoch(incomplete): 0.164928462772\n",
      "Epoch: 1 global_step 12925 i 4229 Avg loss in epoch(incomplete): 0.164935734322\n",
      "Epoch: 1 global_step 12950 i 4254 Avg loss in epoch(incomplete): 0.164941821959\n",
      "Epoch: 1 global_step 12975 i 4279 Avg loss in epoch(incomplete): 0.164947611999\n",
      "saving\n",
      "Epoch: 1 global_step 13000 i 4304 Avg loss in epoch(incomplete): 0.164949435338\n",
      "Epoch: 1 global_step 13000 i 4304 Avg loss in epoch(incomplete): 0.164949435338\n",
      "Epoch: 1 global_step 13025 i 4329 Avg loss in epoch(incomplete): 0.164951971652\n",
      "Epoch: 1 global_step 13050 i 4354 Avg loss in epoch(incomplete): 0.164953055868\n",
      "Epoch: 1 global_step 13075 i 4379 Avg loss in epoch(incomplete): 0.164950944167\n",
      "Epoch: 1 global_step 13100 i 4404 Avg loss in epoch(incomplete): 0.164955781574\n",
      "Epoch: 1 global_step 13125 i 4429 Avg loss in epoch(incomplete): 0.164946494791\n",
      "Epoch: 1 global_step 13150 i 4454 Avg loss in epoch(incomplete): 0.164945778331\n",
      "Epoch: 1 global_step 13175 i 4479 Avg loss in epoch(incomplete): 0.164948805548\n",
      "Epoch: 1 global_step 13200 i 4504 Avg loss in epoch(incomplete): 0.164947019304\n",
      "Epoch: 1 global_step 13225 i 4529 Avg loss in epoch(incomplete): 0.164954853114\n",
      "saving\n",
      "Epoch: 1 global_step 13250 i 4554 Avg loss in epoch(incomplete): 0.164952899851\n",
      "Epoch: 1 global_step 13250 i 4554 Avg loss in epoch(incomplete): 0.164952899851\n",
      "Epoch: 1 global_step 13275 i 4579 Avg loss in epoch(incomplete): 0.164946822184\n",
      "Epoch: 1 global_step 13300 i 4604 Avg loss in epoch(incomplete): 0.16494693628\n",
      "Epoch: 1 global_step 13325 i 4629 Avg loss in epoch(incomplete): 0.164944577481\n",
      "Epoch: 1 global_step 13350 i 4654 Avg loss in epoch(incomplete): 0.164943998911\n",
      "Epoch: 1 global_step 13375 i 4679 Avg loss in epoch(incomplete): 0.164944819058\n",
      "Epoch: 1 global_step 13400 i 4704 Avg loss in epoch(incomplete): 0.164938927441\n",
      "Epoch: 1 global_step 13425 i 4729 Avg loss in epoch(incomplete): 0.164937457373\n",
      "Epoch: 1 global_step 13450 i 4754 Avg loss in epoch(incomplete): 0.164943568642\n",
      "Epoch: 1 global_step 13475 i 4779 Avg loss in epoch(incomplete): 0.16494665077\n",
      "saving\n",
      "Epoch: 1 global_step 13500 i 4804 Avg loss in epoch(incomplete): 0.164941755055\n",
      "Epoch: 1 global_step 13500 i 4804 Avg loss in epoch(incomplete): 0.164941755055\n",
      "Epoch: 1 global_step 13525 i 4829 Avg loss in epoch(incomplete): 0.164942170457\n",
      "Epoch: 1 global_step 13550 i 4854 Avg loss in epoch(incomplete): 0.164940106049\n",
      "Epoch: 1 global_step 13575 i 4879 Avg loss in epoch(incomplete): 0.164937922401\n",
      "Epoch: 1 global_step 13600 i 4904 Avg loss in epoch(incomplete): 0.164941426957\n",
      "Epoch: 1 global_step 13625 i 4929 Avg loss in epoch(incomplete): 0.164946431901\n",
      "Epoch: 1 global_step 13650 i 4954 Avg loss in epoch(incomplete): 0.164948200365\n",
      "Epoch: 1 global_step 13675 i 4979 Avg loss in epoch(incomplete): 0.164949814814\n",
      "Epoch: 1 global_step 13700 i 5004 Avg loss in epoch(incomplete): 0.16495068647\n",
      "Epoch: 1 global_step 13725 i 5029 Avg loss in epoch(incomplete): 0.164948862036\n",
      "saving\n",
      "Epoch: 1 global_step 13750 i 5054 Avg loss in epoch(incomplete): 0.164950094712\n",
      "Epoch: 1 global_step 13750 i 5054 Avg loss in epoch(incomplete): 0.164950094712\n",
      "Epoch: 1 global_step 13775 i 5079 Avg loss in epoch(incomplete): 0.164952432631\n",
      "Epoch: 1 global_step 13800 i 5104 Avg loss in epoch(incomplete): 0.164953742473\n",
      "Epoch: 1 global_step 13825 i 5129 Avg loss in epoch(incomplete): 0.164945695109\n",
      "Epoch: 1 global_step 13850 i 5154 Avg loss in epoch(incomplete): 0.164943888786\n",
      "Epoch: 1 global_step 13875 i 5179 Avg loss in epoch(incomplete): 0.164940452371\n",
      "Epoch: 1 global_step 13900 i 5204 Avg loss in epoch(incomplete): 0.164942975364\n",
      "Epoch: 1 global_step 13925 i 5229 Avg loss in epoch(incomplete): 0.164945373555\n",
      "Epoch: 1 global_step 13950 i 5254 Avg loss in epoch(incomplete): 0.164937394097\n",
      "Epoch: 1 global_step 13975 i 5279 Avg loss in epoch(incomplete): 0.164937535507\n",
      "saving\n",
      "Epoch: 1 global_step 14000 i 5304 Avg loss in epoch(incomplete): 0.164930653345\n",
      "Epoch: 1 global_step 14000 i 5304 Avg loss in epoch(incomplete): 0.164930653345\n",
      "Epoch: 1 global_step 14025 i 5329 Avg loss in epoch(incomplete): 0.164929613437\n",
      "Epoch: 1 global_step 14050 i 5354 Avg loss in epoch(incomplete): 0.164929089919\n",
      "Epoch: 1 global_step 14075 i 5379 Avg loss in epoch(incomplete): 0.164926003169\n",
      "Epoch: 1 global_step 14100 i 5404 Avg loss in epoch(incomplete): 0.16492233887\n",
      "Epoch: 1 global_step 14125 i 5429 Avg loss in epoch(incomplete): 0.164923190873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 global_step 14150 i 5454 Avg loss in epoch(incomplete): 0.164920786528\n",
      "Epoch: 1 global_step 14175 i 5479 Avg loss in epoch(incomplete): 0.164918804394\n",
      "Epoch: 1 global_step 14200 i 5504 Avg loss in epoch(incomplete): 0.164915996554\n",
      "Epoch: 1 global_step 14225 i 5529 Avg loss in epoch(incomplete): 0.164907387004\n",
      "saving\n",
      "Epoch: 1 global_step 14250 i 5554 Avg loss in epoch(incomplete): 0.164906795397\n",
      "Epoch: 1 global_step 14250 i 5554 Avg loss in epoch(incomplete): 0.164906795397\n",
      "Epoch: 1 global_step 14275 i 5579 Avg loss in epoch(incomplete): 0.164903761775\n",
      "Epoch: 1 global_step 14300 i 5604 Avg loss in epoch(incomplete): 0.164903590867\n",
      "Epoch: 1 global_step 14325 i 5629 Avg loss in epoch(incomplete): 0.16490052254\n",
      "Epoch: 1 global_step 14350 i 5654 Avg loss in epoch(incomplete): 0.164900508671\n",
      "Epoch: 1 global_step 14375 i 5679 Avg loss in epoch(incomplete): 0.164904170785\n",
      "Epoch: 1 global_step 14400 i 5704 Avg loss in epoch(incomplete): 0.164905507289\n",
      "Epoch: 1 global_step 14425 i 5729 Avg loss in epoch(incomplete): 0.164903270449\n",
      "Epoch: 1 global_step 14450 i 5754 Avg loss in epoch(incomplete): 0.164901425376\n",
      "Epoch: 1 global_step 14475 i 5779 Avg loss in epoch(incomplete): 0.164903726524\n",
      "saving\n",
      "Epoch: 1 global_step 14500 i 5804 Avg loss in epoch(incomplete): 0.164899467549\n",
      "Epoch: 1 global_step 14500 i 5804 Avg loss in epoch(incomplete): 0.164899467549\n",
      "Epoch: 1 global_step 14525 i 5829 Avg loss in epoch(incomplete): 0.164900379639\n",
      "Epoch: 1 global_step 14550 i 5854 Avg loss in epoch(incomplete): 0.164906015364\n",
      "Epoch: 1 global_step 14575 i 5879 Avg loss in epoch(incomplete): 0.164909476247\n",
      "Epoch: 1 global_step 14600 i 5904 Avg loss in epoch(incomplete): 0.164906297885\n",
      "Epoch: 1 global_step 14625 i 5929 Avg loss in epoch(incomplete): 0.164905995203\n",
      "Epoch: 1 global_step 14650 i 5954 Avg loss in epoch(incomplete): 0.164904967799\n",
      "Epoch: 1 global_step 14675 i 5979 Avg loss in epoch(incomplete): 0.164907314028\n",
      "Epoch: 1 global_step 14700 i 6004 Avg loss in epoch(incomplete): 0.164907111298\n",
      "Epoch: 1 global_step 14725 i 6029 Avg loss in epoch(incomplete): 0.164910193949\n",
      "saving\n",
      "Epoch: 1 global_step 14750 i 6054 Avg loss in epoch(incomplete): 0.16490951858\n",
      "Epoch: 1 global_step 14750 i 6054 Avg loss in epoch(incomplete): 0.16490951858\n",
      "Epoch: 1 global_step 14775 i 6079 Avg loss in epoch(incomplete): 0.164906691711\n",
      "Epoch: 1 global_step 14800 i 6104 Avg loss in epoch(incomplete): 0.164906268109\n",
      "Epoch: 1 global_step 14825 i 6129 Avg loss in epoch(incomplete): 0.16491074485\n",
      "Epoch: 1 global_step 14850 i 6154 Avg loss in epoch(incomplete): 0.164909084668\n",
      "Epoch: 1 global_step 14875 i 6179 Avg loss in epoch(incomplete): 0.164911418738\n",
      "Epoch: 1 global_step 14900 i 6204 Avg loss in epoch(incomplete): 0.164911268828\n",
      "Epoch: 1 global_step 14925 i 6229 Avg loss in epoch(incomplete): 0.164912963665\n",
      "Epoch: 1 global_step 14950 i 6254 Avg loss in epoch(incomplete): 0.164914941237\n",
      "Epoch: 1 global_step 14975 i 6279 Avg loss in epoch(incomplete): 0.164917445833\n",
      "saving\n",
      "Epoch: 1 global_step 15000 i 6304 Avg loss in epoch(incomplete): 0.164920600984\n",
      "Epoch: 1 global_step 15000 i 6304 Avg loss in epoch(incomplete): 0.164920600984\n",
      "Epoch: 1 global_step 15025 i 6329 Avg loss in epoch(incomplete): 0.164923796839\n",
      "Epoch: 1 global_step 15050 i 6354 Avg loss in epoch(incomplete): 0.16492214556\n",
      "Epoch: 1 global_step 15075 i 6379 Avg loss in epoch(incomplete): 0.164922169738\n",
      "Epoch: 1 global_step 15100 i 6404 Avg loss in epoch(incomplete): 0.16491941785\n",
      "Epoch: 1 global_step 15125 i 6429 Avg loss in epoch(incomplete): 0.164923719237\n",
      "Epoch: 1 global_step 15150 i 6454 Avg loss in epoch(incomplete): 0.164923405594\n",
      "Epoch: 1 global_step 15175 i 6479 Avg loss in epoch(incomplete): 0.164921848878\n",
      "Epoch: 1 global_step 15200 i 6504 Avg loss in epoch(incomplete): 0.164924521599\n",
      "Epoch: 1 global_step 15225 i 6529 Avg loss in epoch(incomplete): 0.164921053117\n",
      "saving\n",
      "Epoch: 1 global_step 15250 i 6554 Avg loss in epoch(incomplete): 0.164925060206\n",
      "Epoch: 1 global_step 15250 i 6554 Avg loss in epoch(incomplete): 0.164925060206\n",
      "Epoch: 1 global_step 15275 i 6579 Avg loss in epoch(incomplete): 0.164925004868\n",
      "Epoch: 1 global_step 15300 i 6604 Avg loss in epoch(incomplete): 0.164930129956\n",
      "Epoch: 1 global_step 15325 i 6629 Avg loss in epoch(incomplete): 0.164931018992\n",
      "Epoch: 1 global_step 15350 i 6654 Avg loss in epoch(incomplete): 0.164930888451\n",
      "Epoch: 1 global_step 15375 i 6679 Avg loss in epoch(incomplete): 0.164930443035\n",
      "Epoch: 1 global_step 15400 i 6704 Avg loss in epoch(incomplete): 0.164927017382\n",
      "Epoch: 1 global_step 15425 i 6729 Avg loss in epoch(incomplete): 0.164924327376\n",
      "Epoch: 1 global_step 15450 i 6754 Avg loss in epoch(incomplete): 0.164920502041\n",
      "Epoch: 1 global_step 15475 i 6779 Avg loss in epoch(incomplete): 0.164921544015\n",
      "saving\n",
      "Epoch: 1 global_step 15500 i 6804 Avg loss in epoch(incomplete): 0.16492516237\n",
      "Epoch: 1 global_step 15500 i 6804 Avg loss in epoch(incomplete): 0.16492516237\n",
      "Epoch: 1 global_step 15525 i 6829 Avg loss in epoch(incomplete): 0.164922767395\n",
      "Epoch: 1 global_step 15550 i 6854 Avg loss in epoch(incomplete): 0.164923468139\n",
      "Epoch: 1 global_step 15575 i 6879 Avg loss in epoch(incomplete): 0.164921215956\n",
      "Epoch: 1 global_step 15600 i 6904 Avg loss in epoch(incomplete): 0.164915586476\n",
      "Epoch: 1 global_step 15625 i 6929 Avg loss in epoch(incomplete): 0.164915567363\n",
      "Epoch: 1 global_step 15650 i 6954 Avg loss in epoch(incomplete): 0.164916218214\n",
      "Epoch: 1 global_step 15675 i 6979 Avg loss in epoch(incomplete): 0.164916032916\n",
      "Epoch: 1 global_step 15700 i 7004 Avg loss in epoch(incomplete): 0.164918387545\n",
      "Epoch: 1 global_step 15725 i 7029 Avg loss in epoch(incomplete): 0.164921636502\n",
      "saving\n",
      "Epoch: 1 global_step 15750 i 7054 Avg loss in epoch(incomplete): 0.164923092499\n",
      "Epoch: 1 global_step 15750 i 7054 Avg loss in epoch(incomplete): 0.164923092499\n",
      "Epoch: 1 global_step 15775 i 7079 Avg loss in epoch(incomplete): 0.164922226105\n",
      "Epoch: 1 global_step 15800 i 7104 Avg loss in epoch(incomplete): 0.164920591438\n",
      "Epoch: 1 global_step 15825 i 7129 Avg loss in epoch(incomplete): 0.164921057864\n",
      "Epoch: 1 global_step 15850 i 7154 Avg loss in epoch(incomplete): 0.164917160751\n",
      "Epoch: 1 global_step 15875 i 7179 Avg loss in epoch(incomplete): 0.164919159837\n",
      "Epoch: 1 global_step 15900 i 7204 Avg loss in epoch(incomplete): 0.164917954598\n",
      "Epoch: 1 global_step 15925 i 7229 Avg loss in epoch(incomplete): 0.164915341093\n",
      "Epoch: 1 global_step 15950 i 7254 Avg loss in epoch(incomplete): 0.164915742733\n",
      "Epoch: 1 global_step 15975 i 7279 Avg loss in epoch(incomplete): 0.164916359875\n",
      "saving\n",
      "Epoch: 1 global_step 16000 i 7304 Avg loss in epoch(incomplete): 0.164914588768\n",
      "Epoch: 1 global_step 16000 i 7304 Avg loss in epoch(incomplete): 0.164914588768\n",
      "Epoch: 1 global_step 16025 i 7329 Avg loss in epoch(incomplete): 0.164916970293\n",
      "Epoch: 1 global_step 16050 i 7354 Avg loss in epoch(incomplete): 0.164914648224\n",
      "Epoch: 1 global_step 16075 i 7379 Avg loss in epoch(incomplete): 0.164915423396\n",
      "Epoch: 1 global_step 16100 i 7404 Avg loss in epoch(incomplete): 0.164916730664\n",
      "Epoch: 1 global_step 16125 i 7429 Avg loss in epoch(incomplete): 0.164917530765\n",
      "Epoch: 1 global_step 16150 i 7454 Avg loss in epoch(incomplete): 0.164917100769\n",
      "Epoch: 1 global_step 16175 i 7479 Avg loss in epoch(incomplete): 0.164918345705\n",
      "Epoch: 1 global_step 16200 i 7504 Avg loss in epoch(incomplete): 0.164920894499\n",
      "Epoch: 1 global_step 16225 i 7529 Avg loss in epoch(incomplete): 0.164920491712\n",
      "saving\n",
      "Epoch: 1 global_step 16250 i 7554 Avg loss in epoch(incomplete): 0.164920442314\n",
      "Epoch: 1 global_step 16250 i 7554 Avg loss in epoch(incomplete): 0.164920442314\n",
      "Epoch: 1 global_step 16275 i 7579 Avg loss in epoch(incomplete): 0.164918199769\n",
      "Epoch: 1 global_step 16300 i 7604 Avg loss in epoch(incomplete): 0.164917699194\n",
      "Epoch: 1 global_step 16325 i 7629 Avg loss in epoch(incomplete): 0.164921382853\n",
      "Epoch: 1 global_step 16350 i 7654 Avg loss in epoch(incomplete): 0.164917406039\n",
      "Epoch: 1 global_step 16375 i 7679 Avg loss in epoch(incomplete): 0.164916790739\n",
      "Epoch: 1 global_step 16400 i 7704 Avg loss in epoch(incomplete): 0.164919303285\n",
      "Epoch: 1 global_step 16425 i 7729 Avg loss in epoch(incomplete): 0.164921788576\n",
      "Epoch: 1 global_step 16450 i 7754 Avg loss in epoch(incomplete): 0.164919528138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 global_step 16475 i 7779 Avg loss in epoch(incomplete): 0.164918970372\n",
      "saving\n",
      "Epoch: 1 global_step 16500 i 7804 Avg loss in epoch(incomplete): 0.164920085619\n",
      "Epoch: 1 global_step 16500 i 7804 Avg loss in epoch(incomplete): 0.164920085619\n",
      "Epoch: 1 global_step 16525 i 7829 Avg loss in epoch(incomplete): 0.16491861543\n",
      "Epoch: 1 global_step 16550 i 7854 Avg loss in epoch(incomplete): 0.164920925906\n",
      "Epoch: 1 global_step 16575 i 7879 Avg loss in epoch(incomplete): 0.164920603189\n",
      "Epoch: 1 global_step 16600 i 7904 Avg loss in epoch(incomplete): 0.164920714564\n",
      "Epoch: 1 global_step 16625 i 7929 Avg loss in epoch(incomplete): 0.164921935466\n",
      "Epoch: 1 global_step 16650 i 7954 Avg loss in epoch(incomplete): 0.16492284878\n",
      "Epoch: 1 global_step 16675 i 7979 Avg loss in epoch(incomplete): 0.164922436187\n",
      "Epoch: 1 global_step 16700 i 8004 Avg loss in epoch(incomplete): 0.164922870952\n",
      "Epoch: 1 global_step 16725 i 8029 Avg loss in epoch(incomplete): 0.164918744917\n",
      "saving\n",
      "Epoch: 1 global_step 16750 i 8054 Avg loss in epoch(incomplete): 0.164918420588\n",
      "Epoch: 1 global_step 16750 i 8054 Avg loss in epoch(incomplete): 0.164918420588\n",
      "Epoch: 1 global_step 16775 i 8079 Avg loss in epoch(incomplete): 0.164922907174\n",
      "Epoch: 1 global_step 16800 i 8104 Avg loss in epoch(incomplete): 0.164921179642\n",
      "Epoch: 1 global_step 16825 i 8129 Avg loss in epoch(incomplete): 0.164920397053\n",
      "Epoch: 1 global_step 16850 i 8154 Avg loss in epoch(incomplete): 0.164921774667\n",
      "Epoch: 1 global_step 16875 i 8179 Avg loss in epoch(incomplete): 0.164916744688\n",
      "Epoch: 1 global_step 16900 i 8204 Avg loss in epoch(incomplete): 0.164915178401\n",
      "Epoch: 1 global_step 16925 i 8229 Avg loss in epoch(incomplete): 0.164914457245\n",
      "Epoch: 1 global_step 16950 i 8254 Avg loss in epoch(incomplete): 0.164916932969\n",
      "Epoch: 1 global_step 16975 i 8279 Avg loss in epoch(incomplete): 0.164918508435\n",
      "saving\n",
      "Epoch: 1 global_step 17000 i 8304 Avg loss in epoch(incomplete): 0.164919137686\n",
      "Epoch: 1 global_step 17000 i 8304 Avg loss in epoch(incomplete): 0.164919137686\n",
      "Epoch: 1 global_step 17025 i 8329 Avg loss in epoch(incomplete): 0.164921164287\n",
      "Epoch: 1 global_step 17050 i 8354 Avg loss in epoch(incomplete): 0.164921565506\n",
      "Epoch: 1 global_step 17075 i 8379 Avg loss in epoch(incomplete): 0.164918595161\n",
      "Epoch: 1 global_step 17100 i 8404 Avg loss in epoch(incomplete): 0.164918505273\n",
      "Epoch: 1 global_step 17125 i 8429 Avg loss in epoch(incomplete): 0.164915221323\n",
      "Epoch: 1 global_step 17150 i 8454 Avg loss in epoch(incomplete): 0.164917494282\n",
      "Epoch: 1 global_step 17175 i 8479 Avg loss in epoch(incomplete): 0.164916875356\n",
      "Epoch: 1 global_step 17200 i 8504 Avg loss in epoch(incomplete): 0.164916560508\n",
      "Epoch: 1 global_step 17225 i 8529 Avg loss in epoch(incomplete): 0.164919407509\n",
      "saving\n",
      "Epoch: 1 global_step 17250 i 8554 Avg loss in epoch(incomplete): 0.164916633211\n",
      "Epoch: 1 global_step 17250 i 8554 Avg loss in epoch(incomplete): 0.164916633211\n",
      "Epoch: 1 global_step 17275 i 8579 Avg loss in epoch(incomplete): 0.164914479176\n",
      "Epoch: 1 global_step 17300 i 8604 Avg loss in epoch(incomplete): 0.164911236755\n",
      "Epoch: 1 global_step 17325 i 8629 Avg loss in epoch(incomplete): 0.164908264866\n",
      "Epoch: 1 global_step 17350 i 8654 Avg loss in epoch(incomplete): 0.164905719698\n",
      "Epoch: 1 global_step 17375 i 8679 Avg loss in epoch(incomplete): 0.164907701161\n",
      "saving\n",
      "Epoch: 1 global_step 17390 i 8694 Avg loss in epoch(incomplete): 0.164907232534\n",
      "Epoch: 2 global_step 17400 i 9 Avg loss in epoch(incomplete): 0.16387193352\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: shuffle_batch_1/random_shuffle_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](shuffle_batch_1/random_shuffle_queue, Cast_3, Cast_2)]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-e45f2269448c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             summary = sess.run(summary_op, feed_dict={X: batch_X,\n\u001b[0;32m---> 39\u001b[0;31m                                                     Y: batch_Y})\n\u001b[0m\u001b[1;32m     40\u001b[0m             summaryv = sess.run(summary_op, feed_dict={X: batch_Xv,\n\u001b[1;32m     41\u001b[0m                                                     Y: batch_Yv})\n",
      "\u001b[0;32m/Users/yakir/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yakir/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yakir/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yakir/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yakir/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yakir/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if tf.gfile.Exists('log/' + modelname):\n",
    "   tf.gfile.DeleteRecursively('log/' + modelname) \n",
    "\n",
    "# train\n",
    "\n",
    "print_every = 25\n",
    "save_every = 250\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    if global_step_to_load is None:\n",
    "        global_step = 0\n",
    "    else:\n",
    "        saver.restore(sess, 'log/%s-%d' % (modelname, global_step_to_load))\n",
    "        global_step = global_step_to_load\n",
    "    \n",
    "#    print(layer)\n",
    "    \n",
    "    writer = tf.summary.FileWriter('log/' + modelname + '/train', sess.graph)\n",
    "    writerv = tf.summary.FileWriter('log/' + modelname + '/valid')\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    if global_step_to_load is None:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for i in range(num_batches_in_train):\n",
    "            batch_X, batch_Y = sess.run([seq_batch, label_batch])\n",
    "            batch_Xv, batch_Yv = sess.run([seqv_batch, labelv_batch])\n",
    "            _, _loss = sess.run([update, loss],\n",
    "                            feed_dict={X: batch_X, Y: batch_Y})\n",
    "            total_loss += _loss #/ num_batches_in_train\n",
    "            \n",
    "            summary = sess.run(summary_op, feed_dict={X: batch_X,\n",
    "                                                    Y: batch_Y})\n",
    "            summaryv = sess.run(summary_op, feed_dict={X: batch_Xv,\n",
    "                                                    Y: batch_Yv})\n",
    "#            writer.add_summary(summary, global_step=epoch*num_batches_in_train + i)\n",
    "#            writerv.add_summary(summaryv, global_step=epoch*num_batches_in_train + i)\n",
    "            writer.add_summary(summary, global_step=global_step)\n",
    "            writerv.add_summary(summaryv, global_step=global_step)\n",
    "            \n",
    "            global_step += 1\n",
    "            \n",
    "            if global_step % save_every == 0:\n",
    "                print('saving')\n",
    "                print('Epoch:',epoch,'global_step',global_step,'i',i,'Avg loss in epoch(incomplete):',total_loss / (i+1))\n",
    "                saver.save(sess, 'log/%s' % modelname, global_step=global_step)\n",
    "                \n",
    "            if global_step % print_every == 0:\n",
    "                print('Epoch:',epoch,'global_step',global_step,'i',i,'Avg loss in epoch(incomplete):',total_loss / (i+1))\n",
    "        \n",
    "        print('saving')\n",
    "        print('Epoch:',epoch,'global_step',global_step,'i',i,'Avg loss in epoch(incomplete):',total_loss / (i+1))\n",
    "\n",
    "        saver.save(sess, 'log/%s' % modelname, global_step=global_step)\n",
    "    \n",
    "    writer.close()\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from log/motifconv-17390\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: shuffle_batch_1/random_shuffle_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](shuffle_batch_1/random_shuffle_queue, Cast_3, Cast_2)]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# get test data\n",
    "\n",
    "global_step_to_load_test = 17390\n",
    "\n",
    "\n",
    "scores = []\n",
    "labels = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver(max_to_keep=None)\n",
    "    saver.restore(sess, 'log/%s-%d' % (modelname, global_step_to_load_test))\n",
    "    \n",
    "    idx = 0\n",
    "    while idx < 45458 / batch_size:\n",
    "        batch_Xt, batch_Yt = sess.run([seqt_batch, labelt_batch])\n",
    "        batch_logits = sess.run(logits, feed_dict={X: batch_Xt, Y: batch_Yt})\n",
    "        scores.append(batch_logits)\n",
    "        labels.append(batch_Yt)\n",
    "        #print('asdf')\n",
    "        idx += 1\n",
    "        if idx % 100 == 0:\n",
    "            print(idx)\n",
    "\n",
    "scores_arr = np.concatenate(scores, axis=0)\n",
    "labels_arr = np.concatenate(labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies:\n",
      "[ 0.92912088  0.98846154  0.99094505  0.99454945  0.97520879  0.97378022\n",
      "  0.9752967   0.90749451  0.98142857  0.97835165  0.94134066  0.96804396\n",
      "  0.94942857  0.96786813  0.90402198  0.94010989  0.94386813  0.98325275\n",
      "  0.97925275  0.92118681  0.99        0.91628571  0.97127473  0.92942857]\n",
      "aucs:\n",
      "[0.45687305433691361, 0.7971208766775193, 0.65130680800264606, 0.50415036904446209, 0.61617300228627991, 0.61123845168467639, 0.51833535945177633, 0.4547736015859114, 0.70696365760110891, 0.65810168362800203, 0.57230948783091395, 0.66478549748009474, 0.48582936860560988, 0.64030893229942132, 0.36862873366530086, 0.37547499128681661, 0.36538954001749241, 0.61694390929798448, 0.66325267355420947, 0.57135079409007383, 0.59488369993864487, 0.41554219182938618, 0.77945814328265295, 0.47860540209671881]\n",
      "auprcs:\n",
      "[0.062992902461802072, 0.034374914796597829, 0.015497500929958722, 0.0076064435546530753, 0.035430268805852469, 0.036651741574993672, 0.025535563624608223, 0.083213222270400955, 0.039241636613088798, 0.03729926764662448, 0.074073714537902652, 0.055984640434671773, 0.047657042048887786, 0.050602835359980468, 0.069979882660757248, 0.043733199266303015, 0.040325181830009653, 0.024475399730805997, 0.037293204171186117, 0.094601716824429513, 0.013916922743852566, 0.067558982069532481, 0.077649492664900788, 0.066804526320242821]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>aucs</th>\n",
       "      <th>auprcs</th>\n",
       "      <th>props</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SydhHuvecGata2Ucd</th>\n",
       "      <td>0.943868</td>\n",
       "      <td>0.365390</td>\n",
       "      <td>0.040325</td>\n",
       "      <td>0.056132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SydhHuvecCfosUcd</th>\n",
       "      <td>0.904022</td>\n",
       "      <td>0.368629</td>\n",
       "      <td>0.069980</td>\n",
       "      <td>0.095978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SydhHuvecCjun</th>\n",
       "      <td>0.940110</td>\n",
       "      <td>0.375475</td>\n",
       "      <td>0.043733</td>\n",
       "      <td>0.059890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtaHuvecCtcf</th>\n",
       "      <td>0.916286</td>\n",
       "      <td>0.415542</td>\n",
       "      <td>0.067559</td>\n",
       "      <td>0.083714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HaibGm12891Pu1Pcr1x</th>\n",
       "      <td>0.907495</td>\n",
       "      <td>0.454774</td>\n",
       "      <td>0.083213</td>\n",
       "      <td>0.092505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BroadHuvecCtcf</th>\n",
       "      <td>0.929121</td>\n",
       "      <td>0.456873</td>\n",
       "      <td>0.062993</td>\n",
       "      <td>0.070879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UwHuvecCtcf</th>\n",
       "      <td>0.929429</td>\n",
       "      <td>0.478605</td>\n",
       "      <td>0.066805</td>\n",
       "      <td>0.070571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SydhGm12891NfkbTnfaIggrab</th>\n",
       "      <td>0.949429</td>\n",
       "      <td>0.485829</td>\n",
       "      <td>0.047657</td>\n",
       "      <td>0.050571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HaibGm12891Pax5c20V0416101</th>\n",
       "      <td>0.994549</td>\n",
       "      <td>0.504150</td>\n",
       "      <td>0.007606</td>\n",
       "      <td>0.005451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HaibGm12891Pou2f2Pcr1x</th>\n",
       "      <td>0.975297</td>\n",
       "      <td>0.518335</td>\n",
       "      <td>0.025536</td>\n",
       "      <td>0.024703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtaGm12891Ctcf</th>\n",
       "      <td>0.921187</td>\n",
       "      <td>0.571351</td>\n",
       "      <td>0.094602</td>\n",
       "      <td>0.078813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HaibHuvecPol24h8V0416101</th>\n",
       "      <td>0.941341</td>\n",
       "      <td>0.572309</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.058659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtaHuvecCmyc</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.594884</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HaibGm12891Pol2Pcr1x</th>\n",
       "      <td>0.973780</td>\n",
       "      <td>0.611238</td>\n",
       "      <td>0.036652</td>\n",
       "      <td>0.026220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HaibGm12891Pol24h8Pcr1x</th>\n",
       "      <td>0.975209</td>\n",
       "      <td>0.616173</td>\n",
       "      <td>0.035430</td>\n",
       "      <td>0.024791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SydhHuvecMax</th>\n",
       "      <td>0.983253</td>\n",
       "      <td>0.616944</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>0.016747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SydhGm12891Pol2Iggmus</th>\n",
       "      <td>0.967868</td>\n",
       "      <td>0.640309</td>\n",
       "      <td>0.050603</td>\n",
       "      <td>0.032132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BroadHuvecPol2b</th>\n",
       "      <td>0.990945</td>\n",
       "      <td>0.651307</td>\n",
       "      <td>0.015498</td>\n",
       "      <td>0.009055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HaibGm12891Yy1sc281V0416101</th>\n",
       "      <td>0.978352</td>\n",
       "      <td>0.658102</td>\n",
       "      <td>0.037299</td>\n",
       "      <td>0.021648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SydhHuvecPol2</th>\n",
       "      <td>0.979253</td>\n",
       "      <td>0.663253</td>\n",
       "      <td>0.037293</td>\n",
       "      <td>0.020747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HaibHuvecPol2Pcr1x</th>\n",
       "      <td>0.968044</td>\n",
       "      <td>0.664785</td>\n",
       "      <td>0.055985</td>\n",
       "      <td>0.031956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HaibGm12891Taf1Pcr1x</th>\n",
       "      <td>0.981429</td>\n",
       "      <td>0.706964</td>\n",
       "      <td>0.039242</td>\n",
       "      <td>0.018571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UtaHuvecPol2</th>\n",
       "      <td>0.971275</td>\n",
       "      <td>0.779458</td>\n",
       "      <td>0.077649</td>\n",
       "      <td>0.028725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BroadHuvecEzh239875</th>\n",
       "      <td>0.988462</td>\n",
       "      <td>0.797121</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>0.011538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = np.mean((scores_arr > 0).astype(int) == labels_arr.astype(int), axis=0)\n",
    "\n",
    "print('accuracies:')\n",
    "print(accuracies)\n",
    "\n",
    "import sklearn.metrics\n",
    "print('aucs:')\n",
    "aucs = [sklearn.metrics.roc_auc_score(labels_arr[:,i],scores_arr[:,i]) for i in xrange(scores_arr.shape[1])]\n",
    "print(aucs)\n",
    "\n",
    "import sklearn.metrics\n",
    "def prec_recall(ys_true, ys_hat):\n",
    "    ys, xs, thresholds = sklearn.metrics.precision_recall_curve(ys_true, ys_hat)\n",
    "    return sklearn.metrics.auc(xs, ys, reorder=True)\n",
    "\n",
    "print('auprcs:')\n",
    "auprcs = [prec_recall(labels_arr[:,i],scores_arr[:,i]) for i in xrange(scores_arr.shape[1])]\n",
    "print(auprcs)\n",
    "\n",
    "props = np.mean(labels_arr, axis=0)\n",
    "\n",
    "import json\n",
    "ids = sorted(json.loads(info['tf_to_pos'].replace(\"'\", '\"')).keys())\n",
    "\n",
    "from IPython.display import display_pretty, display_html\n",
    "import pandas as pd\n",
    "results = pd.DataFrame({'props':props, 'acc':accuracies, 'auprcs':auprcs, 'aucs':aucs}, index=ids).sort_values(by='aucs')\n",
    "display_html(results.to_html(), raw=True)\n",
    "results.to_csv('stats.' + modelname + '.tsv', index_label='id', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
